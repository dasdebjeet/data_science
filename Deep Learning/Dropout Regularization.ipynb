{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6cec1da5-523d-4ad3-a75f-46b14de810dc",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dropout Regularization\n",
    "\n",
    "Overfitting and underfitting are common problems in machine learning. Overfitting happens when a model perfectly learns during training but performs poorly during testing. The model will have a higher accuracy score on the training dataset but a lower accuracy score on the testing.\n",
    "\n",
    "Underfitting occurs when the model can neither learn from the training data nor make predictions using a testing dataset. This model underperforms both in training and in testing. This model is too simple to learn anything.\n",
    "\n",
    "Overfitting problem is more common than underfitting. We have many techniques that can handle overfitting such as cross-validation, data augmentation, feature selection, early stopping, and dropout regularization. We will focus on the dropout regularization technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76859e0-b78c-43be-b2bb-9352aace01c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fcb0f5f-ee01-4bce-91f7-86a614aea3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../datasets/sonar_dataset.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594c9811-c5fb-4e0a-9423-d806b0ba2e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      51      52      53      54      55      56      57  \\\n",
       "0  0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "\n",
       "       58      59  60  \n",
       "0  0.0090  0.0032   R  \n",
       "1  0.0052  0.0044   R  \n",
       "2  0.0095  0.0078   R  \n",
       "3  0.0040  0.0117   R  \n",
       "4  0.0107  0.0094   R  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc26589-2c4b-405a-b420-daa8105577d7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee5191f8-f1cd-419a-be74-c49f3668acd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208, 61)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "356faf8b-dccd-4209-ab76-453584463799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "            51, 52, 53, 54, 55, 56, 57, 58, 59, 60],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d7bdac-7be0-42a1-81ca-b0a63bbe1c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(60, axis=1)\n",
    "y = df[60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c61c028-cd47-4819-bb94-3b7220941f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0       1       2       3       4       5       6       7       8   \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "\n",
       "       9   ...      50      51      52      53      54      55      56  \\\n",
       "0  0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180   \n",
       "1  0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
       "2  0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
       "3  0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
       "4  0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
       "\n",
       "       57      58      59  \n",
       "0  0.0084  0.0090  0.0032  \n",
       "1  0.0049  0.0052  0.0044  \n",
       "2  0.0164  0.0095  0.0078  \n",
       "3  0.0044  0.0040  0.0117  \n",
       "4  0.0048  0.0107  0.0094  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0877000f-43e0-422d-b90f-620dff334136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    R\n",
       "1    R\n",
       "2    R\n",
       "3    R\n",
       "4    R\n",
       "Name: 60, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15baa12b-792c-44ed-a46f-598ad0fd4ed7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99338c24-8c85-4546-92c8-6935d3abf655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1a4a36b-dc3f-4b08-bbfb-f299a93840a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtl_count = y.value_counts()[0]\n",
    "rck_count = y.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4afd2450-8999-439c-b60f-7c3099053115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use(['dark_background'])\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.title(\"Minerals Visualization\")\n",
    "plt.ylabel('Quantity')\n",
    "plt.xlabel('Minerals')\n",
    "plt.bar(['Metal', 'Rock'], [mtl_count, rck_count], color=['#aaa9ad', '#5A4D41'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a9f30e-c9d2-4689-9ad6-939aba4528f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d16632da-bda7-4e01-8ef2-291db15ecc1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "10   1\n",
       "102  0\n",
       "69   1\n",
       "58   1\n",
       "145  0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(data=y, drop_first=True)\n",
    "y.sample(5) # R ---> 0, M ---> 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0ba124-7704-4aba-8ec7-612ef43d6c30",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train, test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08dd7757-d241-49f0-9e5e-00d4b0e6a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d5bfb635-a9cc-4dd8-9d3a-2c92f0cbb95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(166, 60)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3aa88270-ee74-4c1c-8cf8-626c75fc5f89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 60)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159ce19-7ca1-4979-9b49-3d847229a5ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build Model without Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8de13cab-d2c2-48cc-a564-b908a5d990f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef1fcca5-f586-48f3-9706-65414fd96ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim=60, activation=\"relu\"),\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")        \n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ac2d9b6-d367-4886-924b-167da4207b8b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 1s 2ms/step - loss: 0.6888 - accuracy: 0.5904\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6674 - accuracy: 0.6145\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6491 - accuracy: 0.6627\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.6867\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.7349\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7651\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7530\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.7711\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.4992 - accuracy: 0.7530\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7590\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4429 - accuracy: 0.8133\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4320 - accuracy: 0.8193\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4017 - accuracy: 0.8494\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8614\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3647 - accuracy: 0.8373\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3696 - accuracy: 0.8373\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3643 - accuracy: 0.8735\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 0.3338 - accuracy: 0.8554\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2963 - accuracy: 0.9036\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3217 - accuracy: 0.8554\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8735\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.8916\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2622 - accuracy: 0.9157\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.2459 - accuracy: 0.9217\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2365 - accuracy: 0.9337\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.9277\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2271 - accuracy: 0.9157\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9398\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9458\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1958 - accuracy: 0.9217\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1648 - accuracy: 0.9398\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1600 - accuracy: 0.9639\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1631 - accuracy: 0.9578\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9639\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9699\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.1206 - accuracy: 0.9759\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1123 - accuracy: 0.9639\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1056 - accuracy: 0.9699\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9639\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.1014 - accuracy: 0.9699\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0777 - accuracy: 0.9880\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0860 - accuracy: 0.9880\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0660 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0616 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0568 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0732 - accuracy: 0.9880\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0548 - accuracy: 0.9880\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0426 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0275 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0207 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0181 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0130 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0105 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0094 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0090 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0047 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e729819900>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6574c19d-f5e0-4c5b-899a-cf02fba6f693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.4745 - accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4744507968425751, 0.8333333134651184]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "959d6d48-75a0-46cd-a860-e620169390a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4c80d7d3-5cb0-40a3-8663-0514b62348fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "522c7a5d-cd7e-4c52-b946-9bf7b667cd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd1a936a-438b-44b5-bc56-26ab7036945b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "161  0\n",
       "15   1\n",
       "73   1\n",
       "96   1\n",
       "166  0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3cddeea8-0a98-4483-8b4b-481e95d4b635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.86        26\n",
      "           1       0.76      0.81      0.79        16\n",
      "\n",
      "    accuracy                           0.83        42\n",
      "   macro avg       0.82      0.83      0.83        42\n",
      "weighted avg       0.84      0.83      0.83        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c536b7af-7bea-4ad2-8742-08d314a7e6cf",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Build Model with Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0335355-ba2c-4922-b9f3-6e02cf999b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = keras.Sequential([\n",
    "    keras.layers.Dense(60, input_dim=60, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(30, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "\n",
    "    keras.layers.Dense(15, activation=\"relu\"),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    \n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")        \n",
    "])\n",
    "\n",
    "model_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a834c47-56f8-4cb2-89e2-00f36339ed5e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "21/21 [==============================] - 1s 2ms/step - loss: 0.7404 - accuracy: 0.4940\n",
      "Epoch 2/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7501 - accuracy: 0.4398\n",
      "Epoch 3/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7200 - accuracy: 0.4940\n",
      "Epoch 4/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7136 - accuracy: 0.5181\n",
      "Epoch 5/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6762 - accuracy: 0.6145\n",
      "Epoch 6/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6834 - accuracy: 0.5181\n",
      "Epoch 7/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.7071 - accuracy: 0.5120\n",
      "Epoch 8/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6946 - accuracy: 0.5422\n",
      "Epoch 9/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6829 - accuracy: 0.5843\n",
      "Epoch 10/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6894 - accuracy: 0.5241\n",
      "Epoch 11/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6849 - accuracy: 0.5482\n",
      "Epoch 12/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6934 - accuracy: 0.5422\n",
      "Epoch 13/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6860 - accuracy: 0.5482\n",
      "Epoch 14/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6850 - accuracy: 0.5723\n",
      "Epoch 15/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5783\n",
      "Epoch 16/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6684 - accuracy: 0.6084\n",
      "Epoch 17/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6981 - accuracy: 0.5000\n",
      "Epoch 18/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.5843\n",
      "Epoch 19/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6651 - accuracy: 0.5482\n",
      "Epoch 20/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.5723\n",
      "Epoch 21/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6205\n",
      "Epoch 22/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6402 - accuracy: 0.6807\n",
      "Epoch 23/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.6386\n",
      "Epoch 24/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.6325\n",
      "Epoch 25/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6506 - accuracy: 0.6747\n",
      "Epoch 26/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5808 - accuracy: 0.7048\n",
      "Epoch 27/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.6566\n",
      "Epoch 28/100\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 0.5816 - accuracy: 0.7108\n",
      "Epoch 29/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5760 - accuracy: 0.6867\n",
      "Epoch 30/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5934 - accuracy: 0.6988\n",
      "Epoch 31/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.6687\n",
      "Epoch 32/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.6014 - accuracy: 0.6205\n",
      "Epoch 33/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.6747\n",
      "Epoch 34/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5903 - accuracy: 0.6988\n",
      "Epoch 35/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5855 - accuracy: 0.6747\n",
      "Epoch 36/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5978 - accuracy: 0.6386\n",
      "Epoch 37/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7289\n",
      "Epoch 38/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7410\n",
      "Epoch 39/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7229\n",
      "Epoch 40/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7771\n",
      "Epoch 41/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7349\n",
      "Epoch 42/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.8253\n",
      "Epoch 43/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7289\n",
      "Epoch 44/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5801 - accuracy: 0.7108\n",
      "Epoch 45/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.8253\n",
      "Epoch 46/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4606 - accuracy: 0.7892\n",
      "Epoch 47/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7229\n",
      "Epoch 48/100\n",
      "21/21 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7590\n",
      "Epoch 49/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4738 - accuracy: 0.8012\n",
      "Epoch 50/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.5226 - accuracy: 0.7289\n",
      "Epoch 51/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7590\n",
      "Epoch 52/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.7590\n",
      "Epoch 53/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4633 - accuracy: 0.7590\n",
      "Epoch 54/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4535 - accuracy: 0.7952\n",
      "Epoch 55/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4844 - accuracy: 0.8072\n",
      "Epoch 56/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8313\n",
      "Epoch 57/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.7530\n",
      "Epoch 58/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.7831\n",
      "Epoch 59/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4359 - accuracy: 0.8012\n",
      "Epoch 60/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.7771\n",
      "Epoch 61/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4427 - accuracy: 0.7952\n",
      "Epoch 62/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8373\n",
      "Epoch 63/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4564 - accuracy: 0.8193\n",
      "Epoch 64/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4101 - accuracy: 0.8313\n",
      "Epoch 65/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.7892\n",
      "Epoch 66/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4331 - accuracy: 0.7952\n",
      "Epoch 67/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4098 - accuracy: 0.8193\n",
      "Epoch 68/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4565 - accuracy: 0.7711\n",
      "Epoch 69/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.4206 - accuracy: 0.7892\n",
      "Epoch 70/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3778 - accuracy: 0.8133\n",
      "Epoch 71/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.8434\n",
      "Epoch 72/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8253\n",
      "Epoch 73/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3861 - accuracy: 0.8012\n",
      "Epoch 74/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3941 - accuracy: 0.8434\n",
      "Epoch 75/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3945 - accuracy: 0.8494\n",
      "Epoch 76/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8313\n",
      "Epoch 77/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.4052 - accuracy: 0.8253\n",
      "Epoch 78/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3354 - accuracy: 0.8675\n",
      "Epoch 79/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8313\n",
      "Epoch 80/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8253\n",
      "Epoch 81/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3849 - accuracy: 0.8012\n",
      "Epoch 82/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3496 - accuracy: 0.8193\n",
      "Epoch 83/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3900 - accuracy: 0.8373\n",
      "Epoch 84/100\n",
      "21/21 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.8494\n",
      "Epoch 85/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3212 - accuracy: 0.8373\n",
      "Epoch 86/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3145 - accuracy: 0.8675\n",
      "Epoch 87/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3474 - accuracy: 0.8434\n",
      "Epoch 88/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2742 - accuracy: 0.8916\n",
      "Epoch 89/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3183 - accuracy: 0.8675\n",
      "Epoch 90/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3446 - accuracy: 0.8614\n",
      "Epoch 91/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8434\n",
      "Epoch 92/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8614\n",
      "Epoch 93/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.8976\n",
      "Epoch 94/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2703 - accuracy: 0.8855\n",
      "Epoch 95/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2928 - accuracy: 0.8916\n",
      "Epoch 96/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2653 - accuracy: 0.8976\n",
      "Epoch 97/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2996 - accuracy: 0.8554\n",
      "Epoch 98/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.3460 - accuracy: 0.8735\n",
      "Epoch 99/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2821 - accuracy: 0.8434\n",
      "Epoch 100/100\n",
      "21/21 [==============================] - 0s 2ms/step - loss: 0.2990 - accuracy: 0.8614\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1e72bd8f610>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(X_train, y_train, epochs=100, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "de2758eb-f026-4390-8556-3959b883652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.3062 - accuracy: 0.9048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.30618634819984436, 0.9047619104385376]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8f768852-db45-467e-bfe3-54a877497993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred_1 = model_1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2ada7d6-a27d-496d-a39b-982039a798da",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_1 = np.round(y_pred_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f94286f2-9aff-4c89-94dc-c3f624ca4ce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bb1194b-3f27-4be5-bf56-1d576196013c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     R\n",
       "161  0\n",
       "15   1\n",
       "73   1\n",
       "96   1\n",
       "166  0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bfa13145-c927-4452-916c-2838c68d9021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        26\n",
      "           1       0.88      0.88      0.88        16\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.90      0.90      0.90        42\n",
      "weighted avg       0.90      0.90      0.90        42\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(classification_report(y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e22258e-94a4-4838-9216-94911760922a",
   "metadata": {},
   "source": [
    "\n",
    "So from above _classification_report_ of both the models, we see that the model with _Dropout_ performs very well"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
