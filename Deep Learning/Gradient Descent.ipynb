{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae268806-3848-4c9f-9124-3d199f9738c9",
   "metadata": {},
   "source": [
    "# Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb74859f-de10-4953-b63d-1af33199c251",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83846e35-95d1-4110-af4f-e19d43b1db0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\Data Science\\datasets\\insurance_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb5458db-c79f-424f-a082-dae6221efae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  bought_insurance\n",
       "0   22                 0\n",
       "1   25                 0\n",
       "2   47                 1\n",
       "3   52                 0\n",
       "4   46                 1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2befbc24-c2a5-4c9e-bac9-940b8318dd2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b56bf97-6982-45b8-9514-17d98b22e391",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['age'], df['bought_insurance'], test_size=0.1, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6fa911c7-d013-49dc-b33f-71f35f797f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = X_train.copy()\n",
    "X_train_scaled = X_train_scaled/100\n",
    "\n",
    "X_test_scaled = X_test.copy()\n",
    "X_test_scaled = X_test_scaled/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10343af0-ffe0-4394-951a-df6c519953fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20    0.21\n",
       " 6     0.55\n",
       " 26    0.23\n",
       " 5     0.56\n",
       " 22    0.40\n",
       " 12    0.27\n",
       " 18    0.19\n",
       " 1     0.25\n",
       " 9     0.61\n",
       " 13    0.29\n",
       " 11    0.28\n",
       " 23    0.45\n",
       " 15    0.55\n",
       " 3     0.52\n",
       " 25    0.54\n",
       " 14    0.49\n",
       " 2     0.47\n",
       " 24    0.50\n",
       " 19    0.18\n",
       " 16    0.25\n",
       " 21    0.26\n",
       " 17    0.58\n",
       " 0     0.22\n",
       " 4     0.46\n",
       " Name: age, dtype: float64,\n",
       " 8     0.62\n",
       " 7     0.60\n",
       " 10    0.18\n",
       " Name: age, dtype: float64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13de5e68-7feb-4700-a77b-c0aac2f2518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85bc3e0-309c-4824-8126-b04cb5b879df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(1, input_shape=(1,), activation='sigmoid', kernel_initializer='ones', bias_initializer='zeros')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a4de1fe-81db-4e59-adab-366ac1f9fb83",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "1/1 [==============================] - 0s 485ms/step - loss: 0.6642 - accuracy: 0.5000\n",
      "Epoch 2/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6641 - accuracy: 0.5000\n",
      "Epoch 3/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6640 - accuracy: 0.5000\n",
      "Epoch 4/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6639 - accuracy: 0.5000\n",
      "Epoch 5/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6637 - accuracy: 0.5000\n",
      "Epoch 6/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6636 - accuracy: 0.5000\n",
      "Epoch 7/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.5000\n",
      "Epoch 8/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6634 - accuracy: 0.5000\n",
      "Epoch 9/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6633 - accuracy: 0.5000\n",
      "Epoch 10/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6632 - accuracy: 0.5000\n",
      "Epoch 11/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6631 - accuracy: 0.5000\n",
      "Epoch 12/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6630 - accuracy: 0.5000\n",
      "Epoch 13/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6629 - accuracy: 0.5000\n",
      "Epoch 14/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6628 - accuracy: 0.5000\n",
      "Epoch 15/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6627 - accuracy: 0.5000\n",
      "Epoch 16/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6626 - accuracy: 0.5000\n",
      "Epoch 17/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6625 - accuracy: 0.5000\n",
      "Epoch 18/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6624 - accuracy: 0.5000\n",
      "Epoch 19/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6623 - accuracy: 0.5000\n",
      "Epoch 20/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6622 - accuracy: 0.5000\n",
      "Epoch 21/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6621 - accuracy: 0.5000\n",
      "Epoch 22/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6620 - accuracy: 0.5000\n",
      "Epoch 23/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.5000\n",
      "Epoch 24/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.5000\n",
      "Epoch 25/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6617 - accuracy: 0.5000\n",
      "Epoch 26/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6616 - accuracy: 0.5000\n",
      "Epoch 27/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6615 - accuracy: 0.5000\n",
      "Epoch 28/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6614 - accuracy: 0.5000\n",
      "Epoch 29/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6613 - accuracy: 0.5000\n",
      "Epoch 30/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6612 - accuracy: 0.5000\n",
      "Epoch 31/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6611 - accuracy: 0.5000\n",
      "Epoch 32/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6610 - accuracy: 0.5000\n",
      "Epoch 33/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6609 - accuracy: 0.5000\n",
      "Epoch 34/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6608 - accuracy: 0.5000\n",
      "Epoch 35/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.5000\n",
      "Epoch 36/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6606 - accuracy: 0.5000\n",
      "Epoch 37/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6605 - accuracy: 0.5000\n",
      "Epoch 38/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.5000\n",
      "Epoch 39/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6603 - accuracy: 0.5000\n",
      "Epoch 40/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6602 - accuracy: 0.5000\n",
      "Epoch 41/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6601 - accuracy: 0.5000\n",
      "Epoch 42/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6600 - accuracy: 0.5000\n",
      "Epoch 43/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6599 - accuracy: 0.5000\n",
      "Epoch 44/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6598 - accuracy: 0.5000\n",
      "Epoch 45/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6597 - accuracy: 0.5000\n",
      "Epoch 46/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6596 - accuracy: 0.5000\n",
      "Epoch 47/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6595 - accuracy: 0.5000\n",
      "Epoch 48/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6594 - accuracy: 0.5000\n",
      "Epoch 49/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.5000\n",
      "Epoch 50/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6592 - accuracy: 0.5000\n",
      "Epoch 51/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6591 - accuracy: 0.5000\n",
      "Epoch 52/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6590 - accuracy: 0.5000\n",
      "Epoch 53/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6589 - accuracy: 0.5000\n",
      "Epoch 54/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6588 - accuracy: 0.5000\n",
      "Epoch 55/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.5000\n",
      "Epoch 56/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6586 - accuracy: 0.5000\n",
      "Epoch 57/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6585 - accuracy: 0.5000\n",
      "Epoch 58/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.5000\n",
      "Epoch 59/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6584 - accuracy: 0.5000\n",
      "Epoch 60/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.5000\n",
      "Epoch 61/700\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6582 - accuracy: 0.5000\n",
      "Epoch 62/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6581 - accuracy: 0.5000\n",
      "Epoch 63/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6580 - accuracy: 0.5000\n",
      "Epoch 64/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6579 - accuracy: 0.5000\n",
      "Epoch 65/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6578 - accuracy: 0.5000\n",
      "Epoch 66/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6577 - accuracy: 0.5000\n",
      "Epoch 67/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6576 - accuracy: 0.5000\n",
      "Epoch 68/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6575 - accuracy: 0.5000\n",
      "Epoch 69/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6574 - accuracy: 0.5000\n",
      "Epoch 70/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6573 - accuracy: 0.5000\n",
      "Epoch 71/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6572 - accuracy: 0.5000\n",
      "Epoch 72/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6571 - accuracy: 0.5000\n",
      "Epoch 73/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6570 - accuracy: 0.5000\n",
      "Epoch 74/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6569 - accuracy: 0.5000\n",
      "Epoch 75/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6568 - accuracy: 0.5000\n",
      "Epoch 76/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6567 - accuracy: 0.5000\n",
      "Epoch 77/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6566 - accuracy: 0.5000\n",
      "Epoch 78/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6565 - accuracy: 0.5000\n",
      "Epoch 79/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6564 - accuracy: 0.5000\n",
      "Epoch 80/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6564 - accuracy: 0.5000\n",
      "Epoch 81/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.5000\n",
      "Epoch 82/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6562 - accuracy: 0.5000\n",
      "Epoch 83/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6561 - accuracy: 0.5000\n",
      "Epoch 84/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6560 - accuracy: 0.5000\n",
      "Epoch 85/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6559 - accuracy: 0.5000\n",
      "Epoch 86/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6558 - accuracy: 0.5000\n",
      "Epoch 87/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6557 - accuracy: 0.5000\n",
      "Epoch 88/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6556 - accuracy: 0.5000\n",
      "Epoch 89/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6555 - accuracy: 0.5000\n",
      "Epoch 90/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6554 - accuracy: 0.5000\n",
      "Epoch 91/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.5000\n",
      "Epoch 92/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6552 - accuracy: 0.5000\n",
      "Epoch 93/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6551 - accuracy: 0.5000\n",
      "Epoch 94/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6550 - accuracy: 0.5000\n",
      "Epoch 95/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.5000\n",
      "Epoch 96/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6549 - accuracy: 0.5000\n",
      "Epoch 97/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6548 - accuracy: 0.5000\n",
      "Epoch 98/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6547 - accuracy: 0.5000\n",
      "Epoch 99/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6546 - accuracy: 0.5000\n",
      "Epoch 100/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.5000\n",
      "Epoch 101/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6544 - accuracy: 0.5000\n",
      "Epoch 102/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6543 - accuracy: 0.5000\n",
      "Epoch 103/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6542 - accuracy: 0.5000\n",
      "Epoch 104/700\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6541 - accuracy: 0.5000\n",
      "Epoch 105/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6540 - accuracy: 0.5000\n",
      "Epoch 106/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6539 - accuracy: 0.5000\n",
      "Epoch 107/700\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6539 - accuracy: 0.5000\n",
      "Epoch 108/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6538 - accuracy: 0.5000\n",
      "Epoch 109/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6537 - accuracy: 0.5000\n",
      "Epoch 110/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6536 - accuracy: 0.5000\n",
      "Epoch 111/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6535 - accuracy: 0.5000\n",
      "Epoch 112/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6534 - accuracy: 0.5000\n",
      "Epoch 113/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6533 - accuracy: 0.5000\n",
      "Epoch 114/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6532 - accuracy: 0.5000\n",
      "Epoch 115/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6531 - accuracy: 0.5000\n",
      "Epoch 116/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6530 - accuracy: 0.5000\n",
      "Epoch 117/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.5000\n",
      "Epoch 118/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6529 - accuracy: 0.5000\n",
      "Epoch 119/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.5000\n",
      "Epoch 120/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6527 - accuracy: 0.5000\n",
      "Epoch 121/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6526 - accuracy: 0.5000\n",
      "Epoch 122/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6525 - accuracy: 0.5000\n",
      "Epoch 123/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.5000\n",
      "Epoch 124/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6523 - accuracy: 0.5000\n",
      "Epoch 125/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.5000\n",
      "Epoch 126/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6521 - accuracy: 0.5000\n",
      "Epoch 127/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6521 - accuracy: 0.5000\n",
      "Epoch 128/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6520 - accuracy: 0.5000\n",
      "Epoch 129/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6519 - accuracy: 0.5000\n",
      "Epoch 130/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6518 - accuracy: 0.5000\n",
      "Epoch 131/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6517 - accuracy: 0.5000\n",
      "Epoch 132/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6516 - accuracy: 0.5000\n",
      "Epoch 133/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6515 - accuracy: 0.5000\n",
      "Epoch 134/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.5000\n",
      "Epoch 135/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6513 - accuracy: 0.5000\n",
      "Epoch 136/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6513 - accuracy: 0.5000\n",
      "Epoch 137/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6512 - accuracy: 0.5000\n",
      "Epoch 138/700\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6511 - accuracy: 0.5000\n",
      "Epoch 139/700\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6510 - accuracy: 0.5000\n",
      "Epoch 140/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6509 - accuracy: 0.5000\n",
      "Epoch 141/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6508 - accuracy: 0.5000\n",
      "Epoch 142/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6507 - accuracy: 0.5000\n",
      "Epoch 143/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6506 - accuracy: 0.5000\n",
      "Epoch 144/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6506 - accuracy: 0.5000\n",
      "Epoch 145/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6505 - accuracy: 0.5000\n",
      "Epoch 146/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6504 - accuracy: 0.5000\n",
      "Epoch 147/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.5000\n",
      "Epoch 148/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6502 - accuracy: 0.5000\n",
      "Epoch 149/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6501 - accuracy: 0.5000\n",
      "Epoch 150/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6500 - accuracy: 0.5000\n",
      "Epoch 151/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6499 - accuracy: 0.5000\n",
      "Epoch 152/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6499 - accuracy: 0.5000\n",
      "Epoch 153/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6498 - accuracy: 0.5000\n",
      "Epoch 154/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6497 - accuracy: 0.5000\n",
      "Epoch 155/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6496 - accuracy: 0.5000\n",
      "Epoch 156/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6495 - accuracy: 0.5000\n",
      "Epoch 157/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6494 - accuracy: 0.5000\n",
      "Epoch 158/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.5000\n",
      "Epoch 159/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6493 - accuracy: 0.5000\n",
      "Epoch 160/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6492 - accuracy: 0.5000\n",
      "Epoch 161/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.5000\n",
      "Epoch 162/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6490 - accuracy: 0.5000\n",
      "Epoch 163/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6489 - accuracy: 0.5000\n",
      "Epoch 164/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6488 - accuracy: 0.5000\n",
      "Epoch 165/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.5000\n",
      "Epoch 166/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6487 - accuracy: 0.5000\n",
      "Epoch 167/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6486 - accuracy: 0.5000\n",
      "Epoch 168/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6485 - accuracy: 0.5000\n",
      "Epoch 169/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6484 - accuracy: 0.5000\n",
      "Epoch 170/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.5000\n",
      "Epoch 171/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6482 - accuracy: 0.5000\n",
      "Epoch 172/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6481 - accuracy: 0.5000\n",
      "Epoch 173/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6481 - accuracy: 0.5000\n",
      "Epoch 174/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6480 - accuracy: 0.5000\n",
      "Epoch 175/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6479 - accuracy: 0.5000\n",
      "Epoch 176/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6478 - accuracy: 0.5000\n",
      "Epoch 177/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6477 - accuracy: 0.5000\n",
      "Epoch 178/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6476 - accuracy: 0.5000\n",
      "Epoch 179/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6476 - accuracy: 0.5000\n",
      "Epoch 180/700\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6475 - accuracy: 0.5000\n",
      "Epoch 181/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6474 - accuracy: 0.5000\n",
      "Epoch 182/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.5000\n",
      "Epoch 183/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6472 - accuracy: 0.5000\n",
      "Epoch 184/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6471 - accuracy: 0.5000\n",
      "Epoch 185/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.5000\n",
      "Epoch 186/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6470 - accuracy: 0.5000\n",
      "Epoch 187/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.5000\n",
      "Epoch 188/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6468 - accuracy: 0.5000\n",
      "Epoch 189/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6467 - accuracy: 0.5000\n",
      "Epoch 190/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6466 - accuracy: 0.5000\n",
      "Epoch 191/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6465 - accuracy: 0.5000\n",
      "Epoch 192/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6465 - accuracy: 0.5000\n",
      "Epoch 193/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.5000\n",
      "Epoch 194/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.5000\n",
      "Epoch 195/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.5000\n",
      "Epoch 196/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.5000\n",
      "Epoch 197/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6460 - accuracy: 0.5000\n",
      "Epoch 198/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6460 - accuracy: 0.5000\n",
      "Epoch 199/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6459 - accuracy: 0.5000\n",
      "Epoch 200/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6458 - accuracy: 0.5000\n",
      "Epoch 201/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6457 - accuracy: 0.5000\n",
      "Epoch 202/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6456 - accuracy: 0.5000\n",
      "Epoch 203/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6456 - accuracy: 0.5000\n",
      "Epoch 204/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6455 - accuracy: 0.5000\n",
      "Epoch 205/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.5000\n",
      "Epoch 206/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6453 - accuracy: 0.5000\n",
      "Epoch 207/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.5000\n",
      "Epoch 208/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.5000\n",
      "Epoch 209/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6451 - accuracy: 0.5000\n",
      "Epoch 210/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6450 - accuracy: 0.5000\n",
      "Epoch 211/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6449 - accuracy: 0.5000\n",
      "Epoch 212/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6448 - accuracy: 0.5000\n",
      "Epoch 213/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6447 - accuracy: 0.5000\n",
      "Epoch 214/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6447 - accuracy: 0.5000\n",
      "Epoch 215/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6446 - accuracy: 0.5000\n",
      "Epoch 216/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6445 - accuracy: 0.5000\n",
      "Epoch 217/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.5000\n",
      "Epoch 218/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6443 - accuracy: 0.5000\n",
      "Epoch 219/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6442 - accuracy: 0.5000\n",
      "Epoch 220/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6442 - accuracy: 0.5000\n",
      "Epoch 221/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6441 - accuracy: 0.5000\n",
      "Epoch 222/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.5000\n",
      "Epoch 223/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6439 - accuracy: 0.5000\n",
      "Epoch 224/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.5000\n",
      "Epoch 225/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.5000\n",
      "Epoch 226/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6437 - accuracy: 0.5000\n",
      "Epoch 227/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6436 - accuracy: 0.5000\n",
      "Epoch 228/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6435 - accuracy: 0.5000\n",
      "Epoch 229/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.5000\n",
      "Epoch 230/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.5000\n",
      "Epoch 231/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6433 - accuracy: 0.5000\n",
      "Epoch 232/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6432 - accuracy: 0.5000\n",
      "Epoch 233/700\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6431 - accuracy: 0.5000\n",
      "Epoch 234/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6430 - accuracy: 0.5000\n",
      "Epoch 235/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6430 - accuracy: 0.5000\n",
      "Epoch 236/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.5000\n",
      "Epoch 237/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6428 - accuracy: 0.5000\n",
      "Epoch 238/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6427 - accuracy: 0.5000\n",
      "Epoch 239/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6426 - accuracy: 0.5000\n",
      "Epoch 240/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6426 - accuracy: 0.5000\n",
      "Epoch 241/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6425 - accuracy: 0.5000\n",
      "Epoch 242/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6424 - accuracy: 0.5000\n",
      "Epoch 243/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6423 - accuracy: 0.5000\n",
      "Epoch 244/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6422 - accuracy: 0.5000\n",
      "Epoch 245/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6422 - accuracy: 0.5000\n",
      "Epoch 246/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.5000\n",
      "Epoch 247/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6420 - accuracy: 0.5000\n",
      "Epoch 248/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.5000\n",
      "Epoch 249/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6419 - accuracy: 0.5000\n",
      "Epoch 250/700\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.6418 - accuracy: 0.5000\n",
      "Epoch 251/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6417 - accuracy: 0.5000\n",
      "Epoch 252/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6416 - accuracy: 0.5000\n",
      "Epoch 253/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.5417\n",
      "Epoch 254/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.5417\n",
      "Epoch 255/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6414 - accuracy: 0.5417\n",
      "Epoch 256/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6413 - accuracy: 0.5417\n",
      "Epoch 257/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6412 - accuracy: 0.5417\n",
      "Epoch 258/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6411 - accuracy: 0.5417\n",
      "Epoch 259/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6411 - accuracy: 0.5417\n",
      "Epoch 260/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6410 - accuracy: 0.5417\n",
      "Epoch 261/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6409 - accuracy: 0.5417\n",
      "Epoch 262/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.5417\n",
      "Epoch 263/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6408 - accuracy: 0.5417\n",
      "Epoch 264/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6407 - accuracy: 0.5417\n",
      "Epoch 265/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6406 - accuracy: 0.5417\n",
      "Epoch 266/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.5417\n",
      "Epoch 267/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.5417\n",
      "Epoch 268/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.5417\n",
      "Epoch 269/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6403 - accuracy: 0.5417\n",
      "Epoch 270/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6402 - accuracy: 0.5417\n",
      "Epoch 271/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.5417\n",
      "Epoch 272/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6401 - accuracy: 0.5417\n",
      "Epoch 273/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6400 - accuracy: 0.5417\n",
      "Epoch 274/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6399 - accuracy: 0.5417\n",
      "Epoch 275/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.5833\n",
      "Epoch 276/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6398 - accuracy: 0.5833\n",
      "Epoch 277/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6397 - accuracy: 0.5833\n",
      "Epoch 278/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6396 - accuracy: 0.5833\n",
      "Epoch 279/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6395 - accuracy: 0.5833\n",
      "Epoch 280/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6394 - accuracy: 0.5833\n",
      "Epoch 281/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6394 - accuracy: 0.5833\n",
      "Epoch 282/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6393 - accuracy: 0.5833\n",
      "Epoch 283/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6392 - accuracy: 0.5833\n",
      "Epoch 284/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6391 - accuracy: 0.5833\n",
      "Epoch 285/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6391 - accuracy: 0.5833\n",
      "Epoch 286/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6390 - accuracy: 0.5833\n",
      "Epoch 287/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6389 - accuracy: 0.5833\n",
      "Epoch 288/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6388 - accuracy: 0.5833\n",
      "Epoch 289/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6388 - accuracy: 0.5833\n",
      "Epoch 290/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.5833\n",
      "Epoch 291/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6386 - accuracy: 0.5833\n",
      "Epoch 292/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6385 - accuracy: 0.5833\n",
      "Epoch 293/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6385 - accuracy: 0.5833\n",
      "Epoch 294/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6384 - accuracy: 0.5833\n",
      "Epoch 295/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6383 - accuracy: 0.5833\n",
      "Epoch 296/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6382 - accuracy: 0.5833\n",
      "Epoch 297/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.5833\n",
      "Epoch 298/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6381 - accuracy: 0.5833\n",
      "Epoch 299/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6380 - accuracy: 0.5833\n",
      "Epoch 300/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.5833\n",
      "Epoch 301/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6379 - accuracy: 0.5833\n",
      "Epoch 302/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6378 - accuracy: 0.5833\n",
      "Epoch 303/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.5833\n",
      "Epoch 304/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6376 - accuracy: 0.5833\n",
      "Epoch 305/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6376 - accuracy: 0.5833\n",
      "Epoch 306/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.5833\n",
      "Epoch 307/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6374 - accuracy: 0.5833\n",
      "Epoch 308/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.5833\n",
      "Epoch 309/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6373 - accuracy: 0.5833\n",
      "Epoch 310/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.5833\n",
      "Epoch 311/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6371 - accuracy: 0.5833\n",
      "Epoch 312/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6370 - accuracy: 0.5833\n",
      "Epoch 313/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6370 - accuracy: 0.5833\n",
      "Epoch 314/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6369 - accuracy: 0.5833\n",
      "Epoch 315/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6368 - accuracy: 0.5833\n",
      "Epoch 316/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.5833\n",
      "Epoch 317/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6367 - accuracy: 0.5833\n",
      "Epoch 318/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6366 - accuracy: 0.5833\n",
      "Epoch 319/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6365 - accuracy: 0.5833\n",
      "Epoch 320/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.5833\n",
      "Epoch 321/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6364 - accuracy: 0.5833\n",
      "Epoch 322/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6250\n",
      "Epoch 323/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6250\n",
      "Epoch 324/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6361 - accuracy: 0.6250\n",
      "Epoch 325/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6361 - accuracy: 0.6250\n",
      "Epoch 326/700\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.6360 - accuracy: 0.6250\n",
      "Epoch 327/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6359 - accuracy: 0.6250\n",
      "Epoch 328/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6358 - accuracy: 0.6250\n",
      "Epoch 329/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6358 - accuracy: 0.6250\n",
      "Epoch 330/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6357 - accuracy: 0.6250\n",
      "Epoch 331/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6250\n",
      "Epoch 332/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6356 - accuracy: 0.6250\n",
      "Epoch 333/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6355 - accuracy: 0.6250\n",
      "Epoch 334/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6354 - accuracy: 0.6250\n",
      "Epoch 335/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6353 - accuracy: 0.6250\n",
      "Epoch 336/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6353 - accuracy: 0.6250\n",
      "Epoch 337/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6352 - accuracy: 0.6250\n",
      "Epoch 338/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6351 - accuracy: 0.6250\n",
      "Epoch 339/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6350 - accuracy: 0.6250\n",
      "Epoch 340/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6350 - accuracy: 0.6250\n",
      "Epoch 341/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6349 - accuracy: 0.6250\n",
      "Epoch 342/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6348 - accuracy: 0.6250\n",
      "Epoch 343/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6348 - accuracy: 0.6250\n",
      "Epoch 344/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6347 - accuracy: 0.6250\n",
      "Epoch 345/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6346 - accuracy: 0.6250\n",
      "Epoch 346/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6345 - accuracy: 0.6250\n",
      "Epoch 347/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6345 - accuracy: 0.6250\n",
      "Epoch 348/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6344 - accuracy: 0.6250\n",
      "Epoch 349/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.6667\n",
      "Epoch 350/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6342 - accuracy: 0.6667\n",
      "Epoch 351/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6667\n",
      "Epoch 352/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6341 - accuracy: 0.6667\n",
      "Epoch 353/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6667\n",
      "Epoch 354/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6340 - accuracy: 0.6667\n",
      "Epoch 355/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.6667\n",
      "Epoch 356/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6338 - accuracy: 0.6667\n",
      "Epoch 357/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6667\n",
      "Epoch 358/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6337 - accuracy: 0.6667\n",
      "Epoch 359/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6336 - accuracy: 0.6667\n",
      "Epoch 360/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6667\n",
      "Epoch 361/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6335 - accuracy: 0.6667\n",
      "Epoch 362/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6334 - accuracy: 0.6667\n",
      "Epoch 363/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6333 - accuracy: 0.6667\n",
      "Epoch 364/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.6667\n",
      "Epoch 365/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6332 - accuracy: 0.6667\n",
      "Epoch 366/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6331 - accuracy: 0.6667\n",
      "Epoch 367/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6330 - accuracy: 0.6667\n",
      "Epoch 368/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6330 - accuracy: 0.6667\n",
      "Epoch 369/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6329 - accuracy: 0.6667\n",
      "Epoch 370/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6328 - accuracy: 0.6667\n",
      "Epoch 371/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6327 - accuracy: 0.6667\n",
      "Epoch 372/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6327 - accuracy: 0.6667\n",
      "Epoch 373/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6326 - accuracy: 0.6667\n",
      "Epoch 374/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6667\n",
      "Epoch 375/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6325 - accuracy: 0.6667\n",
      "Epoch 376/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6324 - accuracy: 0.6667\n",
      "Epoch 377/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7083\n",
      "Epoch 378/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6323 - accuracy: 0.7083\n",
      "Epoch 379/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6322 - accuracy: 0.7083\n",
      "Epoch 380/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6321 - accuracy: 0.7083\n",
      "Epoch 381/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7083\n",
      "Epoch 382/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6320 - accuracy: 0.7083\n",
      "Epoch 383/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6319 - accuracy: 0.7083\n",
      "Epoch 384/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.7083\n",
      "Epoch 385/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6318 - accuracy: 0.7083\n",
      "Epoch 386/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6317 - accuracy: 0.7083\n",
      "Epoch 387/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6316 - accuracy: 0.7083\n",
      "Epoch 388/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6316 - accuracy: 0.7083\n",
      "Epoch 389/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6315 - accuracy: 0.7083\n",
      "Epoch 390/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6314 - accuracy: 0.7083\n",
      "Epoch 391/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6313 - accuracy: 0.7083\n",
      "Epoch 392/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6313 - accuracy: 0.7083\n",
      "Epoch 393/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6312 - accuracy: 0.7083\n",
      "Epoch 394/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6311 - accuracy: 0.7083\n",
      "Epoch 395/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6311 - accuracy: 0.7083\n",
      "Epoch 396/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6310 - accuracy: 0.7083\n",
      "Epoch 397/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.7083\n",
      "Epoch 398/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6309 - accuracy: 0.7083\n",
      "Epoch 399/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6308 - accuracy: 0.7083\n",
      "Epoch 400/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.7083\n",
      "Epoch 401/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.7083\n",
      "Epoch 402/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6306 - accuracy: 0.7083\n",
      "Epoch 403/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6305 - accuracy: 0.7083\n",
      "Epoch 404/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6304 - accuracy: 0.7083\n",
      "Epoch 405/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6304 - accuracy: 0.7083\n",
      "Epoch 406/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6303 - accuracy: 0.7083\n",
      "Epoch 407/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.7083\n",
      "Epoch 408/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6302 - accuracy: 0.7083\n",
      "Epoch 409/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6301 - accuracy: 0.7083\n",
      "Epoch 410/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6300 - accuracy: 0.7083\n",
      "Epoch 411/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6300 - accuracy: 0.7083\n",
      "Epoch 412/700\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6299 - accuracy: 0.7083\n",
      "Epoch 413/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.7083\n",
      "Epoch 414/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6298 - accuracy: 0.7083\n",
      "Epoch 415/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6297 - accuracy: 0.7083\n",
      "Epoch 416/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.7083\n",
      "Epoch 417/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6296 - accuracy: 0.7083\n",
      "Epoch 418/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6295 - accuracy: 0.7083\n",
      "Epoch 419/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6294 - accuracy: 0.7083\n",
      "Epoch 420/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.7083\n",
      "Epoch 421/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.7083\n",
      "Epoch 422/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6292 - accuracy: 0.7083\n",
      "Epoch 423/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.7083\n",
      "Epoch 424/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6291 - accuracy: 0.7083\n",
      "Epoch 425/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6290 - accuracy: 0.7083\n",
      "Epoch 426/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.7083\n",
      "Epoch 427/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6289 - accuracy: 0.7083\n",
      "Epoch 428/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6288 - accuracy: 0.7083\n",
      "Epoch 429/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6287 - accuracy: 0.7083\n",
      "Epoch 430/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.7083\n",
      "Epoch 431/700\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.6286 - accuracy: 0.7083\n",
      "Epoch 432/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.7083\n",
      "Epoch 433/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6285 - accuracy: 0.7083\n",
      "Epoch 434/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6284 - accuracy: 0.7083\n",
      "Epoch 435/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.7083\n",
      "Epoch 436/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6283 - accuracy: 0.7083\n",
      "Epoch 437/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6282 - accuracy: 0.7083\n",
      "Epoch 438/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6281 - accuracy: 0.7083\n",
      "Epoch 439/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6281 - accuracy: 0.7083\n",
      "Epoch 440/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.7083\n",
      "Epoch 441/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.7083\n",
      "Epoch 442/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6279 - accuracy: 0.7083\n",
      "Epoch 443/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6278 - accuracy: 0.7083\n",
      "Epoch 444/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.7083\n",
      "Epoch 445/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6277 - accuracy: 0.7083\n",
      "Epoch 446/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6276 - accuracy: 0.7083\n",
      "Epoch 447/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6275 - accuracy: 0.7083\n",
      "Epoch 448/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6275 - accuracy: 0.7083\n",
      "Epoch 449/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6274 - accuracy: 0.7083\n",
      "Epoch 450/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6273 - accuracy: 0.7083\n",
      "Epoch 451/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6273 - accuracy: 0.7083\n",
      "Epoch 452/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.7083\n",
      "Epoch 453/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.7083\n",
      "Epoch 454/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6271 - accuracy: 0.7083\n",
      "Epoch 455/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6270 - accuracy: 0.7083\n",
      "Epoch 456/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.7083\n",
      "Epoch 457/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6269 - accuracy: 0.7083\n",
      "Epoch 458/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6268 - accuracy: 0.7083\n",
      "Epoch 459/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.7083\n",
      "Epoch 460/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6267 - accuracy: 0.7083\n",
      "Epoch 461/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6266 - accuracy: 0.7083\n",
      "Epoch 462/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6265 - accuracy: 0.7083\n",
      "Epoch 463/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6265 - accuracy: 0.7083\n",
      "Epoch 464/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6264 - accuracy: 0.7083\n",
      "Epoch 465/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6263 - accuracy: 0.7083\n",
      "Epoch 466/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6263 - accuracy: 0.7083\n",
      "Epoch 467/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6262 - accuracy: 0.7083\n",
      "Epoch 468/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6261 - accuracy: 0.7083\n",
      "Epoch 469/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6261 - accuracy: 0.7083\n",
      "Epoch 470/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6260 - accuracy: 0.7083\n",
      "Epoch 471/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.7083\n",
      "Epoch 472/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6259 - accuracy: 0.7083\n",
      "Epoch 473/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6258 - accuracy: 0.7083\n",
      "Epoch 474/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.7083\n",
      "Epoch 475/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6257 - accuracy: 0.7083\n",
      "Epoch 476/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6256 - accuracy: 0.7083\n",
      "Epoch 477/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.7083\n",
      "Epoch 478/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6255 - accuracy: 0.7083\n",
      "Epoch 479/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6254 - accuracy: 0.7500\n",
      "Epoch 480/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6253 - accuracy: 0.7500\n",
      "Epoch 481/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6253 - accuracy: 0.7500\n",
      "Epoch 482/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6252 - accuracy: 0.7500\n",
      "Epoch 483/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6252 - accuracy: 0.7500\n",
      "Epoch 484/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6251 - accuracy: 0.7500\n",
      "Epoch 485/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.7500\n",
      "Epoch 486/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.7500\n",
      "Epoch 487/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6249 - accuracy: 0.7500\n",
      "Epoch 488/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6248 - accuracy: 0.7500\n",
      "Epoch 489/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.7500\n",
      "Epoch 490/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6247 - accuracy: 0.7500\n",
      "Epoch 491/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6246 - accuracy: 0.7500\n",
      "Epoch 492/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.7500\n",
      "Epoch 493/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6245 - accuracy: 0.7500\n",
      "Epoch 494/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.7500\n",
      "Epoch 495/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6244 - accuracy: 0.7500\n",
      "Epoch 496/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6243 - accuracy: 0.7500\n",
      "Epoch 497/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6242 - accuracy: 0.7500\n",
      "Epoch 498/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6242 - accuracy: 0.7500\n",
      "Epoch 499/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6241 - accuracy: 0.7500\n",
      "Epoch 500/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6241 - accuracy: 0.7500\n",
      "Epoch 501/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.7500\n",
      "Epoch 502/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6239 - accuracy: 0.7500\n",
      "Epoch 503/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.7500\n",
      "Epoch 504/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6238 - accuracy: 0.7500\n",
      "Epoch 505/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6237 - accuracy: 0.7500\n",
      "Epoch 506/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.7500\n",
      "Epoch 507/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6236 - accuracy: 0.7500\n",
      "Epoch 508/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6235 - accuracy: 0.7500\n",
      "Epoch 509/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.7500\n",
      "Epoch 510/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6234 - accuracy: 0.7500\n",
      "Epoch 511/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6233 - accuracy: 0.7500\n",
      "Epoch 512/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6233 - accuracy: 0.7500\n",
      "Epoch 513/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.7500\n",
      "Epoch 514/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6232 - accuracy: 0.7500\n",
      "Epoch 515/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.7500\n",
      "Epoch 516/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.7500\n",
      "Epoch 517/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6230 - accuracy: 0.7500\n",
      "Epoch 518/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6229 - accuracy: 0.7500\n",
      "Epoch 519/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6228 - accuracy: 0.7500\n",
      "Epoch 520/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6228 - accuracy: 0.7917\n",
      "Epoch 521/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.7917\n",
      "Epoch 522/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6226 - accuracy: 0.7917\n",
      "Epoch 523/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6226 - accuracy: 0.7917\n",
      "Epoch 524/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.7917\n",
      "Epoch 525/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7917\n",
      "Epoch 526/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.7917\n",
      "Epoch 527/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6223 - accuracy: 0.7917\n",
      "Epoch 528/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6223 - accuracy: 0.7917\n",
      "Epoch 529/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6222 - accuracy: 0.7917\n",
      "Epoch 530/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6221 - accuracy: 0.7917\n",
      "Epoch 531/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6221 - accuracy: 0.7917\n",
      "Epoch 532/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6220 - accuracy: 0.7917\n",
      "Epoch 533/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6220 - accuracy: 0.7917\n",
      "Epoch 534/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6219 - accuracy: 0.7917\n",
      "Epoch 535/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6218 - accuracy: 0.7917\n",
      "Epoch 536/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.7917\n",
      "Epoch 537/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6217 - accuracy: 0.7917\n",
      "Epoch 538/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.7917\n",
      "Epoch 539/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6216 - accuracy: 0.7917\n",
      "Epoch 540/700\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.7917\n",
      "Epoch 541/700\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.6215 - accuracy: 0.7917\n",
      "Epoch 542/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6214 - accuracy: 0.7917\n",
      "Epoch 543/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6213 - accuracy: 0.7917\n",
      "Epoch 544/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6213 - accuracy: 0.7917\n",
      "Epoch 545/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6212 - accuracy: 0.7917\n",
      "Epoch 546/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6211 - accuracy: 0.7917\n",
      "Epoch 547/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6211 - accuracy: 0.7917\n",
      "Epoch 548/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.7917\n",
      "Epoch 549/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6210 - accuracy: 0.7917\n",
      "Epoch 550/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6209 - accuracy: 0.7917\n",
      "Epoch 551/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6208 - accuracy: 0.7917\n",
      "Epoch 552/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6208 - accuracy: 0.7917\n",
      "Epoch 553/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6207 - accuracy: 0.7917\n",
      "Epoch 554/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.7917\n",
      "Epoch 555/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6206 - accuracy: 0.7917\n",
      "Epoch 556/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.7917\n",
      "Epoch 557/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6205 - accuracy: 0.7917\n",
      "Epoch 558/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6204 - accuracy: 0.7917\n",
      "Epoch 559/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6203 - accuracy: 0.7917\n",
      "Epoch 560/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6203 - accuracy: 0.7917\n",
      "Epoch 561/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.7917\n",
      "Epoch 562/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6202 - accuracy: 0.7917\n",
      "Epoch 563/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6201 - accuracy: 0.7917\n",
      "Epoch 564/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6200 - accuracy: 0.7917\n",
      "Epoch 565/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.7917\n",
      "Epoch 566/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6199 - accuracy: 0.8333\n",
      "Epoch 567/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6198 - accuracy: 0.8333\n",
      "Epoch 568/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6198 - accuracy: 0.8333\n",
      "Epoch 569/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6197 - accuracy: 0.8333\n",
      "Epoch 570/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6197 - accuracy: 0.8333\n",
      "Epoch 571/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6196 - accuracy: 0.8333\n",
      "Epoch 572/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.8333\n",
      "Epoch 573/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6195 - accuracy: 0.8333\n",
      "Epoch 574/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.8333\n",
      "Epoch 575/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6194 - accuracy: 0.8333\n",
      "Epoch 576/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6193 - accuracy: 0.8333\n",
      "Epoch 577/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6192 - accuracy: 0.8333\n",
      "Epoch 578/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.8333\n",
      "Epoch 579/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6191 - accuracy: 0.8333\n",
      "Epoch 580/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.8333\n",
      "Epoch 581/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6190 - accuracy: 0.8333\n",
      "Epoch 582/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6189 - accuracy: 0.8333\n",
      "Epoch 583/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6189 - accuracy: 0.8333\n",
      "Epoch 584/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6188 - accuracy: 0.8333\n",
      "Epoch 585/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.8333\n",
      "Epoch 586/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6187 - accuracy: 0.8333\n",
      "Epoch 587/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.8333\n",
      "Epoch 588/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6186 - accuracy: 0.8333\n",
      "Epoch 589/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6185 - accuracy: 0.8333\n",
      "Epoch 590/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6184 - accuracy: 0.8333\n",
      "Epoch 591/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6184 - accuracy: 0.8333\n",
      "Epoch 592/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.8333\n",
      "Epoch 593/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6183 - accuracy: 0.8333\n",
      "Epoch 594/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6182 - accuracy: 0.8333\n",
      "Epoch 595/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6181 - accuracy: 0.8333\n",
      "Epoch 596/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6181 - accuracy: 0.8333\n",
      "Epoch 597/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.8333\n",
      "Epoch 598/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.8333\n",
      "Epoch 599/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6179 - accuracy: 0.8333\n",
      "Epoch 600/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6178 - accuracy: 0.8333\n",
      "Epoch 601/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6178 - accuracy: 0.8333\n",
      "Epoch 602/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.8333\n",
      "Epoch 603/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6177 - accuracy: 0.8333\n",
      "Epoch 604/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6176 - accuracy: 0.8333\n",
      "Epoch 605/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6175 - accuracy: 0.8333\n",
      "Epoch 606/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6175 - accuracy: 0.8333\n",
      "Epoch 607/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.8333\n",
      "Epoch 608/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6174 - accuracy: 0.8333\n",
      "Epoch 609/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6173 - accuracy: 0.8333\n",
      "Epoch 610/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6172 - accuracy: 0.8333\n",
      "Epoch 611/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6172 - accuracy: 0.8333\n",
      "Epoch 612/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.8333\n",
      "Epoch 613/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6171 - accuracy: 0.8333\n",
      "Epoch 614/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6170 - accuracy: 0.8333\n",
      "Epoch 615/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6169 - accuracy: 0.8333\n",
      "Epoch 616/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6169 - accuracy: 0.8333\n",
      "Epoch 617/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.8333\n",
      "Epoch 618/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6168 - accuracy: 0.8750\n",
      "Epoch 619/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6167 - accuracy: 0.8750\n",
      "Epoch 620/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6166 - accuracy: 0.8750\n",
      "Epoch 621/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6166 - accuracy: 0.8750\n",
      "Epoch 622/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6165 - accuracy: 0.8750\n",
      "Epoch 623/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.8750\n",
      "Epoch 624/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6164 - accuracy: 0.8750\n",
      "Epoch 625/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6163 - accuracy: 0.8750\n",
      "Epoch 626/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6163 - accuracy: 0.8750\n",
      "Epoch 627/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6162 - accuracy: 0.8750\n",
      "Epoch 628/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.8750\n",
      "Epoch 629/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.8750\n",
      "Epoch 630/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6160 - accuracy: 0.8750\n",
      "Epoch 631/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6160 - accuracy: 0.8750\n",
      "Epoch 632/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.8750\n",
      "Epoch 633/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6159 - accuracy: 0.8750\n",
      "Epoch 634/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.8750\n",
      "Epoch 635/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6158 - accuracy: 0.8750\n",
      "Epoch 636/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6157 - accuracy: 0.8750\n",
      "Epoch 637/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6156 - accuracy: 0.8750\n",
      "Epoch 638/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6156 - accuracy: 0.8750\n",
      "Epoch 639/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6155 - accuracy: 0.8750\n",
      "Epoch 640/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6155 - accuracy: 0.8750\n",
      "Epoch 641/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6154 - accuracy: 0.8750\n",
      "Epoch 642/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6153 - accuracy: 0.8750\n",
      "Epoch 643/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.8750\n",
      "Epoch 644/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6152 - accuracy: 0.8750\n",
      "Epoch 645/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6152 - accuracy: 0.8750\n",
      "Epoch 646/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6151 - accuracy: 0.8750\n",
      "Epoch 647/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6151 - accuracy: 0.8750\n",
      "Epoch 648/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6150 - accuracy: 0.8750\n",
      "Epoch 649/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6149 - accuracy: 0.8750\n",
      "Epoch 650/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6149 - accuracy: 0.8750\n",
      "Epoch 651/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6148 - accuracy: 0.8750\n",
      "Epoch 652/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6148 - accuracy: 0.8750\n",
      "Epoch 653/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6147 - accuracy: 0.8750\n",
      "Epoch 654/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.8750\n",
      "Epoch 655/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6146 - accuracy: 0.8750\n",
      "Epoch 656/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6145 - accuracy: 0.8750\n",
      "Epoch 657/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6145 - accuracy: 0.8750\n",
      "Epoch 658/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.8750\n",
      "Epoch 659/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6144 - accuracy: 0.8750\n",
      "Epoch 660/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6143 - accuracy: 0.8750\n",
      "Epoch 661/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6142 - accuracy: 0.8750\n",
      "Epoch 662/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6142 - accuracy: 0.8750\n",
      "Epoch 663/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6141 - accuracy: 0.8750\n",
      "Epoch 664/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6141 - accuracy: 0.8750\n",
      "Epoch 665/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6140 - accuracy: 0.8750\n",
      "Epoch 666/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.8750\n",
      "Epoch 667/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6139 - accuracy: 0.8750\n",
      "Epoch 668/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6138 - accuracy: 0.8750\n",
      "Epoch 669/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.8750\n",
      "Epoch 670/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6137 - accuracy: 0.8750\n",
      "Epoch 671/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6137 - accuracy: 0.8750\n",
      "Epoch 672/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.8750\n",
      "Epoch 673/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.8750\n",
      "Epoch 674/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6135 - accuracy: 0.8750\n",
      "Epoch 675/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.8750\n",
      "Epoch 676/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6134 - accuracy: 0.8750\n",
      "Epoch 677/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6133 - accuracy: 0.8750\n",
      "Epoch 678/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6133 - accuracy: 0.8750\n",
      "Epoch 679/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6132 - accuracy: 0.8750\n",
      "Epoch 680/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.8750\n",
      "Epoch 681/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6131 - accuracy: 0.8750\n",
      "Epoch 682/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.8750\n",
      "Epoch 683/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6130 - accuracy: 0.8750\n",
      "Epoch 684/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.8750\n",
      "Epoch 685/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.8750\n",
      "Epoch 686/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6128 - accuracy: 0.8750\n",
      "Epoch 687/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6127 - accuracy: 0.8750\n",
      "Epoch 688/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6127 - accuracy: 0.8750\n",
      "Epoch 689/700\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6126 - accuracy: 0.8750\n",
      "Epoch 690/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6126 - accuracy: 0.8750\n",
      "Epoch 691/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6125 - accuracy: 0.8750\n",
      "Epoch 692/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6125 - accuracy: 0.8750\n",
      "Epoch 693/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6124 - accuracy: 0.8750\n",
      "Epoch 694/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6123 - accuracy: 0.8750\n",
      "Epoch 695/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6123 - accuracy: 0.8750\n",
      "Epoch 696/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.8750\n",
      "Epoch 697/700\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.6122 - accuracy: 0.8750\n",
      "Epoch 698/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.8750\n",
      "Epoch 699/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.8750\n",
      "Epoch 700/700\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.6120 - accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13af972c580>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_scaled, y_train, epochs=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "504de3ea-2c21-4fb1-8870-50c3d06bbdd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 121ms/step - loss: 0.4940 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4940451681613922, 1.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3674c510-8d67-4157-88d8-e069078b9d6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6428451 ],\n",
       "       [0.6342728 ],\n",
       "       [0.44289857]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21ac2c8b-3be7-48b5-9b68-84268d37dde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     0.62\n",
       "7     0.60\n",
       "10    0.18\n",
       "Name: age, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c323c00-213a-4382-a5c8-01c6a4a46e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8     1\n",
       "7     1\n",
       "10    0\n",
       "Name: bought_insurance, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78123a21-6f99-4436-b9dc-bb2348ee8e84",
   "metadata": {},
   "source": [
    "<br><br>\n",
    "## _So now we will get weights and see how the pred with sigmoid functon work.._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c9da54a-99fd-4ad6-aa6d-d1a24ae1477c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = mx + c\n",
    "\n",
    "coef, intercept = model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb0ecf85-ad20-4edc-869b-6b79ca1807b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1.8571382]], dtype=float32), array([-0.56369144], dtype=float32))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef, intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4890a24f-e18c-48e8-874e-a9912e2a0f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b905bcdf-49f3-405c-a179-eefd5c33cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_func(age):\n",
    "    w1 = coef\n",
    "    wsum = w1*age + intercept\n",
    "    return sigmoid(wsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e995d2c-6624-408e-8f07-ece094329276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6428451160842816"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so in we can see the peredicted val of our model when X_test = 0.62, get 0.64.. in y_pred which means the person will buy the insurance\n",
    "pred_func(0.62)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89bf5c1a-49d1-474c-8519-5358373eeedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# log loss or binary cross entropy\n",
    "\n",
    "def log_loss(y_true, y_pred):\n",
    "    epln = 1e-15\n",
    "    y_pred_n = [max(i, epln) for i in y_pred]\n",
    "    y_pred_n = [min(i, 1-epln) for i in y_pred_n]\n",
    "    y_pred_n = np.array(y_pred_n)\n",
    "    return -np.mean(y_true*np.log(y_pred_n) + (1-y_true) * np.log(1-y_pred_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "374913f2-05b1-47ac-b94c-44ad58031829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99999386, 0.5       , 0.73105858])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sigmoid_numpy(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "sigmoid_numpy(np.array([12, 0, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "c21e828e-4daf-4bec-977a-e3a7f3e0d812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_dcnt(age, y_true, epochs, loss_thresh):\n",
    "    w1 = 0.0001\n",
    "    bias = 0\n",
    "    l_rate = 0.1\n",
    "    n = len(age)\n",
    "    for i in range(epochs):\n",
    "        wsum = w1*age + bias\n",
    "        y_pred = sigmoid_numpy(wsum)\n",
    "        \n",
    "        loss = log_loss(y_true, y_pred)\n",
    "        \n",
    "        w1_d = (1/n)*np.dot(np.transpose(age), (y_pred-y_true))\n",
    "        bias_d = np.mean((y_pred-y_true))\n",
    "        \n",
    "        w1 = w1*l_rate - w1_d\n",
    "        bias = bias - l_rate*bias_d\n",
    "        \n",
    "        print(f\"Epoch: {i}, w1: {w1}, bias: {bias}, loss: {loss}\")\n",
    "        \n",
    "        if loss<=loss_thresh:\n",
    "            break\n",
    "        \n",
    "    return w1, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1a6dd43d-e909-4a66-b943-2f037b184f2c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, w1: 0.05021404572916755, bias: -9.697916664936727e-07, loss: 0.6931421599409923\n",
      "Epoch: 1, w1: 0.0530769636225658, bias: -0.0004878953426459914, loss: 0.6906800658017004\n",
      "Epoch: 2, w1: 0.05328773961789692, bias: -0.0009904095821301685, loss: 0.6905401858621644\n",
      "Epoch: 3, w1: 0.053348507938129626, bias: -0.0014824061919909782, loss: 0.6905275698585357\n",
      "Epoch: 4, w1: 0.05339968654104528, bias: -0.0019626934782514304, loss: 0.6905222586076606\n",
      "Epoch: 5, w1: 0.053449182095646745, bias: -0.0024314711037885317, loss: 0.6905175184618496\n",
      "Epoch: 6, w1: 0.05349746565736785, bias: -0.0028890104126644005, loss: 0.6905129650139464\n",
      "Epoch: 7, w1: 0.05354459043000071, bias: -0.003335580538162623, loss: 0.6905085706882946\n",
      "Epoch: 8, w1: 0.05359058553222275, bias: -0.0037714444059710204, loss: 0.6905043282012082\n",
      "Epoch: 9, w1: 0.05363547810611131, bias: -0.0041968586554928, loss: 0.6905002316489277\n",
      "Epoch: 10, w1: 0.053679294572490474, bias: -0.004612073777526095, loss: 0.6904962754348682\n",
      "Epoch: 11, w1: 0.05372206071591294, bias: -0.005017334260695928, loss: 0.6904924541992349\n",
      "Epoch: 12, w1: 0.0537638017036332, bias: -0.00541287873506967, loss: 0.6904887628053893\n",
      "Epoch: 13, w1: 0.05380454210054231, bias: -0.005798940112384866, loss: 0.690485196329846\n",
      "Epoch: 14, w1: 0.05384430588354859, bias: -0.006175745722933693, loss: 0.6904817500528923\n",
      "Epoch: 15, w1: 0.0538831164556074, bias: -0.006543517449181001, loss: 0.6904784194496437\n",
      "Epoch: 16, w1: 0.05392099665941863, bias: -0.006902471856193077, loss: 0.6904752001815089\n",
      "Epoch: 17, w1: 0.053957968790800115, bias: -0.0072528203189525615, loss: 0.6904720880880376\n",
      "Epoch: 18, w1: 0.053994054611744655, bias: -0.007594769146633249, loss: 0.6904690791791431\n",
      "Epoch: 19, w1: 0.05402927536316779, bias: -0.007928519703906782, loss: 0.6904661696276732\n",
      "Epoch: 20, w1: 0.054063651777353346, bias: -0.00825426852935159, loss: 0.6904633557623203\n",
      "Epoch: 21, w1: 0.05409720409010404, bias: -0.008572207451032817, loss: 0.6904606340608499\n",
      "Epoch: 22, w1: 0.054129952052603875, bias: -0.008882523699320322, loss: 0.6904580011436378\n",
      "Epoch: 23, w1: 0.0541619149429989, bias: -0.009185400017010365, loss: 0.6904554537674946\n",
      "Epoch: 24, w1: 0.054193111577702985, bias: -0.009481014766814986, loss: 0.6904529888197737\n",
      "Epoch: 25, w1: 0.05422356032243503, bias: -0.00976954203628165, loss: 0.690450603312741\n",
      "Epoch: 26, w1: 0.05425327910299395, bias: -0.010051151740204232, loss: 0.6904482943781997\n",
      "Epoch: 27, w1: 0.054282285415777315, bias: -0.010326009720585002, loss: 0.6904460592623552\n",
      "Epoch: 28, w1: 0.05431059633804984, bias: -0.010594277844205885, loss: 0.6904438953209127\n",
      "Epoch: 29, w1: 0.05433822853796765, bias: -0.010856114097865887, loss: 0.6904418000143915\n",
      "Epoch: 30, w1: 0.05436519828436378, bias: -0.011111672681340256, loss: 0.6904397709036525\n",
      "Epoch: 31, w1: 0.05439152145630073, bias: -0.011361104098115629, loss: 0.6904378056456228\n",
      "Epoch: 32, w1: 0.05441721355239558, bias: -0.011604555243954172, loss: 0.6904359019892136\n",
      "Epoch: 33, w1: 0.05444228969992271, bias: -0.01184216949333842, loss: 0.6904340577714185\n",
      "Epoch: 34, w1: 0.054466764663699783, bias: -0.012074086783847375, loss: 0.6904322709135865\n",
      "Epoch: 35, w1: 0.05449065285476179, bias: -0.012300443698513141, loss: 0.6904305394178601\n",
      "Epoch: 36, w1: 0.05451396833882818, bias: -0.012521373546206322, loss: 0.6904288613637733\n",
      "Epoch: 37, w1: 0.0545367248445682, bias: -0.01273700644009715, loss: 0.6904272349049982\n",
      "Epoch: 38, w1: 0.05455893577166885, bias: -0.012947469374238322, loss: 0.6904256582662378\n",
      "Epoch: 39, w1: 0.05458061419871049, bias: -0.013152886298314325, loss: 0.6904241297402551\n",
      "Epoch: 40, w1: 0.054601772890854265, bias: -0.013353378190601048, loss: 0.6904226476850343\n",
      "Epoch: 41, w1: 0.054622424307346214, bias: -0.013549063129178416, loss: 0.6904212105210653\n",
      "Epoch: 42, w1: 0.05464258060884196, bias: -0.013740056361437752, loss: 0.6904198167287513\n",
      "Epoch: 43, w1: 0.054662253664556695, bias: -0.013926470371924632, loss: 0.690418464845927\n",
      "Epoch: 44, w1: 0.05468145505924417, bias: -0.014108414948556962, loss: 0.6904171534654869\n",
      "Epoch: 45, w1: 0.054700196100009035, bias: -0.014285997247257142, loss: 0.6904158812331183\n",
      "Epoch: 46, w1: 0.05471848782295647, bias: -0.014459321855036174, loss: 0.6904146468451339\n",
      "Epoch: 47, w1: 0.05473634099968275, bias: -0.014628490851566773, loss: 0.690413449046396\n",
      "Epoch: 48, w1: 0.05475376614361062, bias: -0.014793603869281547, loss: 0.690412286628335\n",
      "Epoch: 49, w1: 0.05477077351617354, bias: -0.014954758152031558, loss: 0.690411158427052\n",
      "Epoch: 50, w1: 0.05478737313285173, bias: -0.015112048612339647, loss: 0.6904100633215048\n",
      "Epoch: 51, w1: 0.05480357476906388, bias: -0.015265567887282191, loss: 0.6904090002317718\n",
      "Epoch: 52, w1: 0.054819387965918336, bias: -0.01541540639303202, loss: 0.6904079681173908\n",
      "Epoch: 53, w1: 0.05483482203582618, bias: -0.015561652378094586, loss: 0.6904069659757726\n",
      "Epoch: 54, w1: 0.05484988606798054, bias: -0.01570439197526862, loss: 0.6904059928406774\n",
      "Epoch: 55, w1: 0.054864588933704383, bias: -0.015843709252361806, loss: 0.6904050477807631\n",
      "Epoch: 56, w1: 0.05487893929167078, bias: -0.015979686261691228, loss: 0.6904041298981909\n",
      "Epoch: 57, w1: 0.054892945592997865, bias: -0.016112403088397745, loss: 0.6904032383272939\n",
      "Epoch: 58, w1: 0.05490661608622222, bias: -0.0162419378976026, loss: 0.6904023722333008\n",
      "Epoch: 59, w1: 0.05491995882215282, bias: -0.01636836698043404, loss: 0.6904015308111152\n",
      "Epoch: 60, w1: 0.05493298165860931, bias: -0.016491764798950922, loss: 0.6904007132841464\n",
      "Epoch: 61, w1: 0.05494569226504635, bias: -0.016612204029989832, loss: 0.6903999189031902\n",
      "Epoch: 62, w1: 0.054958098127067714, bias: -0.016729755607961343, loss: 0.6903991469453562\n",
      "Epoch: 63, w1: 0.05497020655083196, bias: -0.016844488766620667, loss: 0.6903983967130424\n",
      "Epoch: 64, w1: 0.054982024667352795, bias: -0.016956471079837256, loss: 0.6903976675329514\n",
      "Epoch: 65, w1: 0.054993559436696565, bias: -0.017065768501387257, loss: 0.6903969587551488\n",
      "Epoch: 66, w1: 0.055004817652078916, bias: -0.01717244540379232, loss: 0.690396269752161\n",
      "Epoch: 67, w1: 0.05501580594386379, bias: -0.0172765646162275, loss: 0.6903955999181107\n",
      "Epoch: 68, w1: 0.0550265307834662, bias: -0.01737818746152061, loss: 0.690394948667889\n",
      "Epoch: 69, w1: 0.05503699848716195, bias: -0.017477373792264755, loss: 0.6903943154363615\n",
      "Epoch: 70, w1: 0.05504721521980581, bias: -0.01757418202606533, loss: 0.6903936996776082\n",
      "Epoch: 71, w1: 0.05505718699846079, bias: -0.01766866917994216, loss: 0.690393100864194\n",
      "Epoch: 72, w1: 0.055066919695940374, bias: -0.01776089090390704, loss: 0.6903925184864695\n",
      "Epoch: 73, w1: 0.055076419044266106, bias: -0.017850901513736465, loss: 0.6903919520519027\n",
      "Epoch: 74, w1: 0.0550856906380421, bias: -0.017938754022958782, loss: 0.6903914010844346\n",
      "Epoch: 75, w1: 0.05509473993774881, bias: -0.018024500174074597, loss: 0.6903908651238645\n",
      "Epoch: 76, w1: 0.055103572272958076, bias: -0.01810819046902883, loss: 0.6903903437252588\n",
      "Epoch: 77, w1: 0.055112192845470746, bias: -0.01818987419895231, loss: 0.6903898364583841\n",
      "Epoch: 78, w1: 0.05512060673237956, bias: -0.018269599473190474, loss: 0.6903893429071655\n",
      "Epoch: 79, w1: 0.055128818889058316, bias: -0.01834741324763615, loss: 0.690388862669162\n",
      "Epoch: 80, w1: 0.05513683415207962, bias: -0.018423361352383223, loss: 0.6903883953550695\n",
      "Epoch: 81, w1: 0.05514465724206266, bias: -0.018497488518717343, loss: 0.6903879405882382\n",
      "Epoch: 82, w1: 0.055152292766452636, bias: -0.01856983840545966, loss: 0.6903874980042128\n",
      "Epoch: 83, w1: 0.055159745222233825, bias: -0.018640453624679004, loss: 0.690387067250291\n",
      "Epoch: 84, w1: 0.055167018998577406, bias: -0.0187093757667877, loss: 0.6903866479850974\n",
      "Epoch: 85, w1: 0.05517411837942598, bias: -0.018776645425035772, loss: 0.6903862398781774\n",
      "Epoch: 86, w1: 0.05518104754601605, bias: -0.018842302219417965, loss: 0.6903858426096043\n",
      "Epoch: 87, w1: 0.05518781057934017, bias: -0.018906384820007623, loss: 0.6903854558696046\n",
      "Epoch: 88, w1: 0.05519441146254994, bias: -0.01896893096973121, loss: 0.6903850793581968\n",
      "Epoch: 89, w1: 0.05520085408330156, bias: -0.01902997750659683, loss: 0.6903847127848438\n",
      "Epoch: 90, w1: 0.05520714223604513, bias: -0.01908956038538987, loss: 0.690384355868121\n",
      "Epoch: 91, w1: 0.05521327962425895, bias: -0.019147714698848524, loss: 0.6903840083353945\n",
      "Epoch: 92, w1: 0.05521926986263042, bias: -0.019204474698331656, loss: 0.6903836699225154\n",
      "Epoch: 93, w1: 0.05522511647918474, bias: -0.019259873813991173, loss: 0.6903833403735232\n",
      "Epoch: 94, w1: 0.05523082291736235, bias: -0.01931394467446081, loss: 0.6903830194403607\n",
      "Epoch: 95, w1: 0.05523639253804673, bias: -0.019366719126072875, loss: 0.6903827068826026\n",
      "Epoch: 96, w1: 0.05524182862154361, bias: -0.0194182282516143, loss: 0.6903824024671912\n",
      "Epoch: 97, w1: 0.0552471343695127, bias: -0.01946850238863304, loss: 0.6903821059681846\n",
      "Epoch: 98, w1: 0.055252312906853104, bias: -0.019517571147305568, loss: 0.6903818171665135\n",
      "Epoch: 99, w1: 0.05525736728354355, bias: -0.019565463427876024, loss: 0.6903815358497472\n",
      "Epoch: 100, w1: 0.05526230047643858, bias: -0.019612207437677272, loss: 0.6903812618118698\n",
      "Epoch: 101, w1: 0.05526711539102156, bias: -0.01965783070774389, loss: 0.690380994853062\n",
      "Epoch: 102, w1: 0.055271814863115803, bias: -0.019702360109026835, loss: 0.6903807347794948\n",
      "Epoch: 103, w1: 0.055276401660554524, bias: -0.019745821868219424, loss: 0.6903804814031279\n",
      "Epoch: 104, w1: 0.05528087848481093, bias: -0.019788241583203837, loss: 0.6903802345415172\n",
      "Epoch: 105, w1: 0.05528524797258915, bias: -0.01982964423812733, loss: 0.6903799940176293\n",
      "Epoch: 106, w1: 0.05528951269737693, bias: -0.019870054218116977, loss: 0.690379759659662\n",
      "Epoch: 107, w1: 0.05529367517096142, bias: -0.01990949532364163, loss: 0.6903795313008732\n",
      "Epoch: 108, w1: 0.05529773784490815, bias: -0.019947990784529572, loss: 0.6903793087794137\n",
      "Epoch: 109, w1: 0.05530170311200507, bias: -0.019985563273650055, loss: 0.6903790919381688\n",
      "Epoch: 110, w1: 0.05530557330767155, bias: -0.020022234920266876, loss: 0.6903788806246031\n",
      "Epoch: 111, w1: 0.055309350711333874, bias: -0.020058027323071742, loss: 0.6903786746906132\n",
      "Epoch: 112, w1: 0.05531303754776759, bias: -0.02009296156290519, loss: 0.6903784739923845\n",
      "Epoch: 113, w1: 0.05531663598840786, bias: -0.02012705821517252, loss: 0.690378278390253\n",
      "Epoch: 114, w1: 0.05532014815262813, bias: -0.020160337361962044, loss: 0.6903780877485725\n",
      "Epoch: 115, w1: 0.055323576108988456, bias: -0.0201928186038728, loss: 0.6903779019355873\n",
      "Epoch: 116, w1: 0.055326921876453716, bias: -0.02022452107155868, loss: 0.6903777208233081\n",
      "Epoch: 117, w1: 0.05533018742558257, bias: -0.020255463436995812, loss: 0.6903775442873928\n",
      "Epoch: 118, w1: 0.05533337467968813, bias: -0.020285663924479756, loss: 0.6903773722070322\n",
      "Epoch: 119, w1: 0.05533648551597058, bias: -0.020315140321359084, loss: 0.6903772044648386\n",
      "Epoch: 120, w1: 0.05533952176662281, bias: -0.02034390998851159, loss: 0.6903770409467396\n",
      "Epoch: 121, w1: 0.055342485219909435, bias: -0.020371989870569332, loss: 0.6903768815418735\n",
      "Epoch: 122, w1: 0.05534537762121998, bias: -0.020399396505898525, loss: 0.6903767261424916\n",
      "Epoch: 123, w1: 0.055348200674096876, bias: -0.020426146036340156, loss: 0.6903765746438607\n",
      "Epoch: 124, w1: 0.0553509560412387, bias: -0.020452254216717067, loss: 0.6903764269441707\n",
      "Epoch: 125, w1: 0.05535364534547945, bias: -0.020477736424113102, loss: 0.6903762829444453\n",
      "Epoch: 126, w1: 0.05535627017074429, bias: -0.020502607666929754, loss: 0.6903761425484553\n",
      "Epoch: 127, w1: 0.05535883206298242, bias: -0.02052688259372572, loss: 0.690376005662634\n",
      "Epoch: 128, w1: 0.05536133253107761, bias: -0.020550575501844488, loss: 0.6903758721959985\n",
      "Epoch: 129, w1: 0.05536377304773677, bias: -0.020573700345835062, loss: 0.6903757420600701\n",
      "Epoch: 130, w1: 0.055366155050357385, bias: -0.02059627074567083, loss: 0.6903756151687993\n",
      "Epoch: 131, w1: 0.055368479941874, bias: -0.020618299994771345, loss: 0.6903754914384933\n",
      "Epoch: 132, w1: 0.055370749091584626, bias: -0.02063980106783179, loss: 0.6903753707877452\n",
      "Epoch: 133, w1: 0.05537296383595705, bias: -0.02066078662846474, loss: 0.6903752531373666\n",
      "Epoch: 134, w1: 0.055375125479416004, bias: -0.02068126903665867, loss: 0.6903751384103208\n",
      "Epoch: 135, w1: 0.05537723529511143, bias: -0.020701260356057676, loss: 0.6903750265316596\n",
      "Epoch: 136, w1: 0.05537929452566836, bias: -0.020720772361066637, loss: 0.6903749174284628\n",
      "Epoch: 137, w1: 0.05538130438391862, bias: -0.020739816543786035, loss: 0.6903748110297768\n",
      "Epoch: 138, w1: 0.05538326605361536, bias: -0.020758404120780494, loss: 0.6903747072665585\n",
      "Epoch: 139, w1: 0.055385180690130056, bias: -0.02077654603968505, loss: 0.6903746060716193\n",
      "Epoch: 140, w1: 0.05538704942113305, bias: -0.02079425298565303, loss: 0.6903745073795706\n",
      "Epoch: 141, w1: 0.05538887334725767, bias: -0.020811535387649325, loss: 0.6903744111267726\n",
      "Epoch: 142, w1: 0.05539065354274855, bias: -0.020828403424592776, loss: 0.6903743172512828\n",
      "Epoch: 143, w1: 0.055392391056094226, bias: -0.020844867031351317, loss: 0.6903742256928084\n",
      "Epoch: 144, w1: 0.055394086910644666, bias: -0.020860935904593342, loss: 0.6903741363926575\n",
      "Epoch: 145, w1: 0.05539574210521403, bias: -0.020876619508498798, loss: 0.6903740492936947\n",
      "Epoch: 146, w1: 0.05539735761466892, bias: -0.020891927080333363, loss: 0.6903739643402957\n",
      "Epoch: 147, w1: 0.05539893439050256, bias: -0.020906867635888938, loss: 0.6903738814783053\n",
      "Epoch: 148, w1: 0.055400473361395156, bias: -0.020921449974793744, loss: 0.6903738006549944\n",
      "Epoch: 149, w1: 0.05540197543376082, bias: -0.02093568268569507, loss: 0.6903737218190217\n",
      "Epoch: 150, w1: 0.055403441492281554, bias: -0.02094957415131778, loss: 0.6903736449203931\n",
      "Epoch: 151, w1: 0.05540487240042813, bias: -0.02096313255340152, loss: 0.6903735699104233\n",
      "Epoch: 152, w1: 0.05540626900096879, bias: -0.020976365877519564, loss: 0.6903734967417018\n",
      "Epoch: 153, w1: 0.05540763211646552, bias: -0.020989281917782113, loss: 0.6903734253680546\n",
      "Epoch: 154, w1: 0.05540896254975855, bias: -0.021001888281426847, loss: 0.6903733557445112\n",
      "Epoch: 155, w1: 0.055410261084439166, bias: -0.021014192393299384, loss: 0.6903732878272706\n",
      "Epoch: 156, w1: 0.05541152848531126, bias: -0.02102620150022634, loss: 0.6903732215736694\n",
      "Epoch: 157, w1: 0.055412765498841776, bias: -0.02103792267528353, loss: 0.6903731569421504\n",
      "Epoch: 158, w1: 0.055413972853600314, bias: -0.02104936282196183, loss: 0.6903730938922307\n",
      "Epoch: 159, w1: 0.05541515126068822, bias: -0.02106052867823318, loss: 0.6903730323844752\n",
      "Epoch: 160, w1: 0.05541630141415754, bias: -0.02107142682051906, loss: 0.6903729723804646\n",
      "Epoch: 161, w1: 0.055417423991419634, bias: -0.021082063667563863, loss: 0.6903729138427698\n",
      "Epoch: 162, w1: 0.05541851965364418, bias: -0.02109244548421537, loss: 0.6903728567349242\n",
      "Epoch: 163, w1: 0.05541958904614867, bias: -0.021102578385114593, loss: 0.6903728010213973\n",
      "Epoch: 164, w1: 0.055420632798778464, bias: -0.021112468338297143, loss: 0.6903727466675704\n",
      "Epoch: 165, w1: 0.05542165152627762, bias: -0.02112212116870827, loss: 0.6903726936397101\n",
      "Epoch: 166, w1: 0.055422645828651126, bias: -0.02113154256163361, loss: 0.6903726419049461\n",
      "Epoch: 167, w1: 0.05542361629151816, bias: -0.02114073806604768, loss: 0.6903725914312472\n",
      "Epoch: 168, w1: 0.05542456348645707, bias: -0.02114971309788208, loss: 0.6903725421873989\n",
      "Epoch: 169, w1: 0.055425487971342086, bias: -0.02115847294321536, loss: 0.6903724941429813\n",
      "Epoch: 170, w1: 0.05542639029067168, bias: -0.02116702276138639, loss: 0.6903724472683482\n",
      "Epoch: 171, w1: 0.0554272709758895, bias: -0.021175367588033064, loss: 0.6903724015346068\n",
      "Epoch: 172, w1: 0.055428130545697174, bias: -0.02118351233805821, loss: 0.6903723569135956\n",
      "Epoch: 173, w1: 0.05542896950635998, bias: -0.02119146180852431, loss: 0.6903723133778685\n",
      "Epoch: 174, w1: 0.055429788352004884, bias: -0.02119922068147888, loss: 0.690372270900672\n",
      "Epoch: 175, w1: 0.055430587564911656, bias: -0.021206793526712064, loss: 0.6903722294559304\n",
      "Epoch: 176, w1: 0.05543136761579687, bias: -0.021214184804448144, loss: 0.690372189018225\n",
      "Epoch: 177, w1: 0.055432128964091186, bias: -0.021221398867972502, loss: 0.6903721495627781\n",
      "Epoch: 178, w1: 0.05543287205820989, bias: -0.021228439966195594, loss: 0.6903721110654368\n",
      "Epoch: 179, w1: 0.05543359733581703, bias: -0.02123531224615546, loss: 0.6903720735026555\n",
      "Epoch: 180, w1: 0.055434305224083255, bias: -0.021242019755460226, loss: 0.6903720368514797\n",
      "Epoch: 181, w1: 0.055434996139937194, bias: -0.021248566444672067, loss: 0.6903720010895321\n",
      "Epoch: 182, w1: 0.055435670490311284, bias: -0.02125495616963396, loss: 0.690371966194996\n",
      "Epoch: 183, w1: 0.05543632867238127, bias: -0.021261192693740712, loss: 0.6903719321466014\n",
      "Epoch: 184, w1: 0.05543697107380016, bias: -0.021267279690155492, loss: 0.6903718989236108\n",
      "Epoch: 185, w1: 0.055437598072926565, bias: -0.021273220743973243, loss: 0.6903718665058053\n",
      "Epoch: 186, w1: 0.055438210039047565, bias: -0.02127901935433222, loss: 0.690371834873471\n",
      "Epoch: 187, w1: 0.05543880733259617, bias: -0.02128467893647488, loss: 0.6903718040073858\n",
      "Epoch: 188, w1: 0.05543939030536359, bias: -0.021290202823759413, loss: 0.6903717738888071\n",
      "Epoch: 189, w1: 0.05543995930070647, bias: -0.02129559426962297, loss: 0.6903717444994597\n",
      "Epoch: 190, w1: 0.05544051465374907, bias: -0.021300856449497894, loss: 0.6903717158215225\n",
      "Epoch: 191, w1: 0.055441056691580747, bias: -0.02130599246268194, loss: 0.6903716878376182\n",
      "Epoch: 192, w1: 0.05544158573344851, bias: -0.021311005334163722, loss: 0.6903716605308009\n",
      "Epoch: 193, w1: 0.05544210209094505, bias: -0.02131589801640433, loss: 0.6903716338845459\n",
      "Epoch: 194, w1: 0.055442606068192235, bias: -0.021320673391076277, loss: 0.6903716078827382\n",
      "Epoch: 195, w1: 0.055443097962020405, bias: -0.021325334270760728, loss: 0.6903715825096626\n",
      "Epoch: 196, w1: 0.05544357806214295, bias: -0.021329883400604044, loss: 0.6903715577499927\n",
      "Epoch: 197, w1: 0.05544404665132714, bias: -0.0213343234599346, loss: 0.6903715335887819\n",
      "Epoch: 198, w1: 0.055444504005560495, bias: -0.02133865706384086, loss: 0.6903715100114534\n",
      "Epoch: 199, w1: 0.05544495039421353, bias: -0.02134288676471159, loss: 0.6903714870037904\n",
      "Epoch: 200, w1: 0.055445386080198236, bias: -0.021347015053739163, loss: 0.690371464551927\n",
      "Epoch: 201, w1: 0.055445811320123065, bias: -0.0213510443623868, loss: 0.6903714426423404\n",
      "Epoch: 202, w1: 0.055446226364443935, bias: -0.02135497706382065, loss: 0.6903714212618407\n",
      "Epoch: 203, w1: 0.05544663145761182, bias: -0.021358815474307534, loss: 0.6903714003975635\n",
      "Epoch: 204, w1: 0.05544702683821673, bias: -0.02136256185457916, loss: 0.6903713800369612\n",
      "Epoch: 205, w1: 0.05544741273912821, bias: -0.02136621841116364, loss: 0.6903713601677949\n",
      "Epoch: 206, w1: 0.055447789387632486, bias: -0.0213697872976851, loss: 0.690371340778127\n",
      "Epoch: 207, w1: 0.05544815700556639, bias: -0.021373270616132086, loss: 0.6903713218563139\n",
      "Epoch: 208, w1: 0.0554485158094479, bias: -0.021376670418095604, loss: 0.6903713033909975\n",
      "Epoch: 209, w1: 0.05544886601060379, bias: -0.021379988705977453, loss: 0.690371285371099\n",
      "Epoch: 210, w1: 0.05544920781529402, bias: -0.02138322743416959, loss: 0.6903712677858111\n",
      "Epoch: 211, w1: 0.05544954142483323, bias: -0.021386388510205228, loss: 0.6903712506245929\n",
      "Epoch: 212, w1: 0.055449867035709345, bias: -0.02138947379588231, loss: 0.6903712338771606\n",
      "Epoch: 213, w1: 0.05545018483969926, bias: -0.021392485108360084, loss: 0.6903712175334831\n",
      "Epoch: 214, w1: 0.0554504950239818, bias: -0.021395424221229347, loss: 0.6903712015837747\n",
      "Epoch: 215, w1: 0.05545079777124797, bias: -0.021398292865557066, loss: 0.6903711860184899\n",
      "Epoch: 216, w1: 0.05545109325980856, bias: -0.021401092730905923, loss: 0.6903711708283161\n",
      "Epoch: 217, w1: 0.05545138166369917, bias: -0.021403825466329428, loss: 0.6903711560041693\n",
      "Epoch: 218, w1: 0.05545166315278269, bias: -0.02140649268134318, loss: 0.6903711415371866\n",
      "Epoch: 219, w1: 0.05545193789284934, bias: -0.021409095946872816, loss: 0.6903711274187222\n",
      "Epoch: 220, w1: 0.055452206045714374, bias: -0.021411636796179277, loss: 0.690371113640342\n",
      "Epoch: 221, w1: 0.05545246776931337, bias: -0.021414116725761826, loss: 0.690371100193817\n",
      "Epoch: 222, w1: 0.05545272321779508, bias: -0.021416537196239482, loss: 0.6903710870711194\n",
      "Epoch: 223, w1: 0.055452972541612564, bias: -0.021418899633211273, loss: 0.6903710742644172\n",
      "Epoch: 224, w1: 0.05545321588761147, bias: -0.021421205428095884, loss: 0.6903710617660698\n",
      "Epoch: 225, w1: 0.05545345339911669, bias: -0.021423455938951164, loss: 0.6903710495686219\n",
      "Epoch: 226, w1: 0.055453685216016756, bias: -0.021425652491274, loss: 0.6903710376648009\n",
      "Epoch: 227, w1: 0.05545391147484624, bias: -0.021427796378781, loss: 0.6903710260475107\n",
      "Epoch: 228, w1: 0.055454132308866054, bias: -0.021429888864170448, loss: 0.6903710147098282\n",
      "Epoch: 229, w1: 0.05545434784814215, bias: -0.021431931179866023, loss: 0.6903710036449989\n",
      "Epoch: 230, w1: 0.055454558219621884, bias: -0.02143392452874265, loss: 0.6903709928464323\n",
      "Epoch: 231, w1: 0.055454763547209046, bias: -0.021435870084834975, loss: 0.6903709823076989\n",
      "Epoch: 232, w1: 0.05545496395183653, bias: -0.021437768994028845, loss: 0.6903709720225244\n",
      "Epoch: 233, w1: 0.05545515955153788, bias: -0.021439622374736195, loss: 0.6903709619847883\n",
      "Epoch: 234, w1: 0.05545535046151656, bias: -0.021441431318553777, loss: 0.690370952188518\n",
      "Epoch: 235, w1: 0.055455536794213944, bias: -0.021443196890906083, loss: 0.690370942627886\n",
      "Epoch: 236, w1: 0.05545571865937548, bias: -0.02144492013167285, loss: 0.6903709332972068\n",
      "Epoch: 237, w1: 0.05545589616411535, bias: -0.02144660205580152, loss: 0.6903709241909325\n",
      "Epoch: 238, w1: 0.05545606941297956, bias: -0.021448243653905033, loss: 0.69037091530365\n",
      "Epoch: 239, w1: 0.055456238508007495, bias: -0.021449845892845272, loss: 0.6903709066300775\n",
      "Epoch: 240, w1: 0.055456403548792055, bias: -0.021451409716302508, loss: 0.6903708981650615\n",
      "Epoch: 241, w1: 0.05545656463253828, bias: -0.02145293604533122, loss: 0.6903708899035731\n",
      "Epoch: 242, w1: 0.0554567218541206, bias: -0.021454425778902563, loss: 0.6903708818407054\n",
      "Epoch: 243, w1: 0.05545687530613871, bias: -0.02145587979443385, loss: 0.6903708739716711\n",
      "Epoch: 244, w1: 0.055457025078972155, bias: -0.021457298948305323, loss: 0.6903708662917977\n",
      "Epoch: 245, w1: 0.055457171260833535, bias: -0.021458684076364542, loss: 0.6903708587965269\n",
      "Epoch: 246, w1: 0.0554573139378204, bias: -0.02146003599441868, loss: 0.6903708514814103\n",
      "Epoch: 247, w1: 0.055457453193966104, bias: -0.02146135549871502, loss: 0.6903708443421074\n",
      "Epoch: 248, w1: 0.05545758911128912, bias: -0.02146264336640991, loss: 0.6903708373743828\n",
      "Epoch: 249, w1: 0.05545772176984148, bias: -0.0214639003560265, loss: 0.6903708305741031\n",
      "Epoch: 250, w1: 0.05545785124775587, bias: -0.021465127207901506, loss: 0.6903708239372359\n",
      "Epoch: 251, w1: 0.055457977621291635, bias: -0.021466324644621216, loss: 0.6903708174598454\n",
      "Epoch: 252, w1: 0.05545810096487978, bias: -0.021467493371447117, loss: 0.6903708111380915\n",
      "Epoch: 253, w1: 0.05545822135116668, bias: -0.021468634076731247, loss: 0.6903708049682269\n",
      "Epoch: 254, w1: 0.05545833885105694, bias: -0.021469747432321634, loss: 0.6903707989465947\n",
      "Epoch: 255, w1: 0.05545845353375522, bias: -0.02147083409395798, loss: 0.6903707930696262\n",
      "Epoch: 256, w1: 0.05545856546680679, bias: -0.021471894701657904, loss: 0.6903707873338397\n",
      "Epoch: 257, w1: 0.05545867471613757, bias: -0.021472929880093874, loss: 0.6903707817358372\n",
      "Epoch: 258, w1: 0.055458781346092736, bias: -0.021473940238961133, loss: 0.6903707762723026\n",
      "Epoch: 259, w1: 0.05545888541947481, bias: -0.021474926373336794, loss: 0.69037077094\n",
      "Epoch: 260, w1: 0.05545898699758048, bias: -0.02147588886403033, loss: 0.6903707657357717\n",
      "Epoch: 261, w1: 0.0554590861402368, bias: -0.02147682827792564, loss: 0.6903707606565362\n",
      "Epoch: 262, w1: 0.05545918290583641, bias: -0.02147774516831496, loss: 0.6903707556992869\n",
      "Epoch: 263, w1: 0.05545927735137193, bias: -0.021478640075224705, loss: 0.6903707508610887\n",
      "Epoch: 264, w1: 0.05545936953246948, bias: -0.02147951352573356, loss: 0.6903707461390783\n",
      "Epoch: 265, w1: 0.055459459503421495, bias: -0.0214803660342829, loss: 0.6903707415304611\n",
      "Epoch: 266, w1: 0.05545954731721874, bias: -0.02148119810297979, loss: 0.6903707370325098\n",
      "Epoch: 267, w1: 0.05545963302558141, bias: -0.021482010221892715, loss: 0.6903707326425632\n",
      "Epoch: 268, w1: 0.055459716678989655, bias: -0.021482802869340206, loss: 0.6903707283580239\n",
      "Epoch: 269, w1: 0.055459798326713314, bias: -0.02148357651217258, loss: 0.6903707241763578\n",
      "Epoch: 270, w1: 0.055459878016840956, bias: -0.021484331606046885, loss: 0.6903707200950912\n",
      "Epoch: 271, w1: 0.05545995579630811, bias: -0.02148506859569528, loss: 0.69037071611181\n",
      "Epoch: 272, w1: 0.05546003171092505, bias: -0.02148578791518697, loss: 0.6903707122241592\n",
      "Epoch: 273, w1: 0.055460105805403614, bias: -0.021486489988183866, loss: 0.6903707084298395\n",
      "Epoch: 274, w1: 0.05546017812338368, bias: -0.0214871752281901, loss: 0.6903707047266076\n",
      "Epoch: 275, w1: 0.05546024870745883, bias: -0.021487844038795573, loss: 0.6903707011122743\n",
      "Epoch: 276, w1: 0.05546031759920134, bias: -0.02148849681391368, loss: 0.690370697584703\n",
      "Epoch: 277, w1: 0.05546038483918681, bias: -0.021489133938013282, loss: 0.6903706941418083\n",
      "Epoch: 278, w1: 0.05546045046701798, bias: -0.021489755786345176, loss: 0.6903706907815552\n",
      "Epoch: 279, w1: 0.05546051452134804, bias: -0.021490362725163095, loss: 0.6903706875019582\n",
      "Epoch: 280, w1: 0.05546057703990344, bias: -0.021490955111939426, loss: 0.690370684301079\n",
      "Epoch: 281, w1: 0.05546063805950615, bias: -0.02149153329557575, loss: 0.6903706811770259\n",
      "Epoch: 282, w1: 0.05546069761609522, bias: -0.021492097616608353, loss: 0.6903706781279535\n",
      "Epoch: 283, w1: 0.055460755744748055, bias: -0.02149264840740876, loss: 0.6903706751520603\n",
      "Epoch: 284, w1: 0.05546081247970099, bias: -0.021493185992379527, loss: 0.690370672247588\n",
      "Epoch: 285, w1: 0.055460867854369614, bias: -0.021493710688145293, loss: 0.690370669412821\n",
      "Epoch: 286, w1: 0.055460921901368226, bias: -0.021494222803739263, loss: 0.6903706666460848\n",
      "Epoch: 287, w1: 0.05546097465252922, bias: -0.02149472264078522, loss: 0.6903706639457453\n",
      "Epoch: 288, w1: 0.05546102613892177, bias: -0.02149521049367518, loss: 0.6903706613102076\n",
      "Epoch: 289, w1: 0.05546107639087011, bias: -0.02149568664974278, loss: 0.6903706587379155\n",
      "Epoch: 290, w1: 0.05546112543797145, bias: -0.021496151389432505, loss: 0.6903706562273496\n",
      "Epoch: 291, w1: 0.05546117330911333, bias: -0.02149660498646487, loss: 0.6903706537770277\n",
      "Epoch: 292, w1: 0.05546122003249071, bias: -0.021497047707997638, loss: 0.6903706513855029\n",
      "Epoch: 293, w1: 0.05546126563562251, bias: -0.021497479814783154, loss: 0.6903706490513631\n",
      "Epoch: 294, w1: 0.05546131014536794, bias: -0.021497901561321937, loss: 0.6903706467732307\n",
      "Epoch: 295, w1: 0.05546135358794212, bias: -0.021498313196012565, loss: 0.6903706445497603\n",
      "Epoch: 296, w1: 0.055461395988931655, bias: -0.02149871496129799, loss: 0.6903706423796395\n",
      "Epoch: 297, w1: 0.05546143737330979, bias: -0.021499107093808312, loss: 0.6903706402615876\n",
      "Epoch: 298, w1: 0.05546147776545086, bias: -0.021499489824500163, loss: 0.690370638194354\n",
      "Epoch: 299, w1: 0.05546151718914489, bias: -0.021499863378792724, loss: 0.6903706361767187\n",
      "Epoch: 300, w1: 0.055461555667611476, bias: -0.02150022797670051, loss: 0.6903706342074912\n",
      "Epoch: 301, w1: 0.05546159322351352, bias: -0.02150058383296292, loss: 0.690370632285509\n",
      "Epoch: 302, w1: 0.05546162987897055, bias: -0.021500931157170756, loss: 0.690370630409638\n",
      "Epoch: 303, w1: 0.05546166565557172, bias: -0.021501270153889626, loss: 0.690370628578771\n",
      "Epoch: 304, w1: 0.05546170057438862, bias: -0.02150160102278046, loss: 0.6903706267918279\n",
      "Epoch: 305, w1: 0.055461734655987596, bias: -0.021501923958717084, loss: 0.6903706250477546\n",
      "Epoch: 306, w1: 0.05546176792044185, bias: -0.02150223915190101, loss: 0.6903706233455215\n",
      "Epoch: 307, w1: 0.05546180038734339, bias: -0.021502546787973448, loss: 0.6903706216841243\n",
      "Epoch: 308, w1: 0.05546183207581442, bias: -0.02150284704812466, loss: 0.6903706200625832\n",
      "Epoch: 309, w1: 0.05546186300451868, bias: -0.02150314010920066, loss: 0.6903706184799413\n",
      "Epoch: 310, w1: 0.05546189319167245, bias: -0.021503426143807385, loss: 0.6903706169352649\n",
      "Epoch: 311, w1: 0.05546192265505523, bias: -0.02150370532041235, loss: 0.6903706154276431\n",
      "Epoch: 312, w1: 0.05546195141202023, bias: -0.021503977803443868, loss: 0.6903706139561864\n",
      "Epoch: 313, w1: 0.05546197947950464, bias: -0.021504243753387896, loss: 0.6903706125200265\n",
      "Epoch: 314, w1: 0.05546200687403951, bias: -0.021504503326882564, loss: 0.690370611118317\n",
      "Epoch: 315, w1: 0.05546203361175957, bias: -0.021504756676810427, loss: 0.6903706097502306\n",
      "Epoch: 316, w1: 0.05546205970841269, bias: -0.021505003952388507, loss: 0.6903706084149605\n",
      "Epoch: 317, w1: 0.05546208517936918, bias: -0.021505245299256178, loss: 0.6903706071117193\n",
      "Epoch: 318, w1: 0.05546211003963082, bias: -0.021505480859560947, loss: 0.6903706058397384\n",
      "Epoch: 319, w1: 0.055462134303839714, bias: -0.021505710772042178, loss: 0.6903706045982675\n",
      "Epoch: 320, w1: 0.055462157986286856, bias: -0.021505935172112797, loss: 0.6903706033865746\n",
      "Epoch: 321, w1: 0.05546218110092069, bias: -0.02150615419193906, loss: 0.6903706022039451\n",
      "Epoch: 322, w1: 0.05546220366135517, bias: -0.02150636796051838, loss: 0.6903706010496817\n",
      "Epoch: 323, w1: 0.055462225680877796, bias: -0.021506576603755316, loss: 0.6903705999231035\n",
      "Epoch: 324, w1: 0.05546224717245762, bias: -0.02150678024453572, loss: 0.6903705988235466\n",
      "Epoch: 325, w1: 0.0554622681487526, bias: -0.021506979002799128, loss: 0.6903705977503626\n",
      "Epoch: 326, w1: 0.05546228862211731, bias: -0.021507172995609374, loss: 0.6903705967029184\n",
      "Epoch: 327, w1: 0.055462308604610044, bias: -0.021507362337223574, loss: 0.6903705956805967\n",
      "Epoch: 328, w1: 0.05546232810800002, bias: -0.02150754713915938, loss: 0.6903705946827946\n",
      "Epoch: 329, w1: 0.05546234714377427, bias: -0.021507727510260696, loss: 0.6903705937089238\n",
      "Epoch: 330, w1: 0.055462365723144405, bias: -0.02150790355676177, loss: 0.6903705927584104\n",
      "Epoch: 331, w1: 0.055462383857053224, bias: -0.021508075382349764, loss: 0.6903705918306938\n",
      "Epoch: 332, w1: 0.05546240155618117, bias: -0.021508243088225815, loss: 0.690370590925227\n",
      "Epoch: 333, w1: 0.05546241883095259, bias: -0.021508406773164658, loss: 0.6903705900414764\n",
      "Epoch: 334, w1: 0.055462435691541925, bias: -0.02150856653357279, loss: 0.690370589178921\n",
      "Epoch: 335, w1: 0.05546245214787965, bias: -0.021508722463545255, loss: 0.6903705883370522\n",
      "Epoch: 336, w1: 0.05546246820965814, bias: -0.021508874654921063, loss: 0.6903705875153738\n",
      "Epoch: 337, w1: 0.05546248388633742, bias: -0.021509023197337274, loss: 0.6903705867134017\n",
      "Epoch: 338, w1: 0.05546249918715066, bias: -0.021509168178281808, loss: 0.6903705859306628\n",
      "Epoch: 339, w1: 0.05546251412110968, bias: -0.021509309683144955, loss: 0.6903705851666957\n",
      "Epoch: 340, w1: 0.055462528697010224, bias: -0.02150944779526968, loss: 0.6903705844210503\n",
      "Epoch: 341, w1: 0.05546254292343715, bias: -0.02150958259600071, loss: 0.6903705836932872\n",
      "Epoch: 342, w1: 0.05546255680876945, bias: -0.021509714164732435, loss: 0.6903705829829772\n",
      "Epoch: 343, w1: 0.0554625703611853, bias: -0.021509842578955676, loss: 0.6903705822897015\n",
      "Epoch: 344, w1: 0.055462583588666715, bias: -0.021509967914303332, loss: 0.6903705816130518\n",
      "Epoch: 345, w1: 0.05546259649900437, bias: -0.021510090244594906, loss: 0.6903705809526293\n",
      "Epoch: 346, w1: 0.05546260909980214, bias: -0.021510209641880003, loss: 0.6903705803080445\n",
      "Epoch: 347, w1: 0.05546262139848162, bias: -0.021510326176480753, loss: 0.6903705796789178\n",
      "Epoch: 348, w1: 0.055462633402286396, bias: -0.02151043991703324, loss: 0.6903705790648783\n",
      "Epoch: 349, w1: 0.055462645118286434, bias: -0.02151055093052792, loss: 0.690370578465564\n",
      "Epoch: 350, w1: 0.055462656553382186, bias: -0.021510659282349062, loss: 0.6903705778806218\n",
      "Epoch: 351, w1: 0.05546266771430865, bias: -0.021510765036313297, loss: 0.690370577309707\n",
      "Epoch: 352, w1: 0.05546267860763933, bias: -0.02151086825470717, loss: 0.6903705767524831\n",
      "Epoch: 353, w1: 0.055462689239790156, bias: -0.02151096899832383, loss: 0.6903705762086219\n",
      "Epoch: 354, w1: 0.05546269961702319, bias: -0.02151106732649885, loss: 0.6903705756778026\n",
      "Epoch: 355, w1: 0.05546270974545037, bias: -0.021511163297145162, loss: 0.6903705751597128\n",
      "Epoch: 356, w1: 0.05546271963103712, bias: -0.021511256966787174, loss: 0.6903705746540466\n",
      "Epoch: 357, w1: 0.05546272927960577, bias: -0.021511348390594053, loss: 0.6903705741605065\n",
      "Epoch: 358, w1: 0.05546273869683914, bias: -0.021511437622412224, loss: 0.6903705736788015\n",
      "Epoch: 359, w1: 0.05546274788828375, bias: -0.021511524714797083, loss: 0.6903705732086478\n",
      "Epoch: 360, w1: 0.05546275685935311, bias: -0.021511609719043957, loss: 0.6903705727497682\n",
      "Epoch: 361, w1: 0.055462765615331, bias: -0.0215116926852183, loss: 0.6903705723018927\n",
      "Epoch: 362, w1: 0.05546277416137446, bias: -0.0215117736621852, loss: 0.690370571864757\n",
      "Epoch: 363, w1: 0.05546278250251689, bias: -0.021511852697638143, loss: 0.6903705714381035\n",
      "Epoch: 364, w1: 0.055462790643671045, bias: -0.021511929838127115, loss: 0.6903705710216811\n",
      "Epoch: 365, w1: 0.05546279858963186, bias: -0.02151200512908601, loss: 0.6903705706152442\n",
      "Epoch: 366, w1: 0.05546280634507934, bias: -0.02151207861485939, loss: 0.6903705702185535\n",
      "Epoch: 367, w1: 0.055462813914581216, bias: -0.021512150338728612, loss: 0.6903705698313752\n",
      "Epoch: 368, w1: 0.05546282130259575, bias: -0.021512220342937316, loss: 0.6903705694534811\n",
      "Epoch: 369, w1: 0.05546282851347437, bias: -0.021512288668716295, loss: 0.6903705690846484\n",
      "Epoch: 370, w1: 0.055462835551464015, bias: -0.02151235535630779, loss: 0.6903705687246603\n",
      "Epoch: 371, w1: 0.055462842420709924, bias: -0.021512420444989196, loss: 0.690370568373304\n",
      "Epoch: 372, w1: 0.05546284912525796, bias: -0.02151248397309618, loss: 0.690370568030373\n",
      "Epoch: 373, w1: 0.05546285566905688, bias: -0.02151254597804527, loss: 0.690370567695665\n",
      "Epoch: 374, w1: 0.05546286205596087, bias: -0.021512606496355894, loss: 0.6903705673689832\n",
      "Epoch: 375, w1: 0.05546286828973166, bias: -0.021512665563671877, loss: 0.6903705670501344\n",
      "Epoch: 376, w1: 0.05546287437404076, bias: -0.021512723214782457, loss: 0.6903705667389316\n",
      "Epoch: 377, w1: 0.05546288031247169, bias: -0.02151277948364275, loss: 0.6903705664351906\n",
      "Epoch: 378, w1: 0.05546288610852208, bias: -0.02151283440339376, loss: 0.6903705661387333\n",
      "Epoch: 379, w1: 0.05546289176560561, bias: -0.021512888006381906, loss: 0.6903705658493843\n",
      "Epoch: 380, w1: 0.055462897287054204, bias: -0.021512940324178057, loss: 0.6903705655669734\n",
      "Epoch: 381, w1: 0.055462902676119856, bias: -0.021512991387596138, loss: 0.6903705652913343\n",
      "Epoch: 382, w1: 0.055462907935976594, bias: -0.021513041226711275, loss: 0.6903705650223046\n",
      "Epoch: 383, w1: 0.05546291306972234, bias: -0.02151308987087751, loss: 0.6903705647597259\n",
      "Epoch: 384, w1: 0.05546291808038074, bias: -0.021513137348745093, loss: 0.6903705645034431\n",
      "Epoch: 385, w1: 0.05546292297090297, bias: -0.021513183688277343, loss: 0.6903705642533057\n",
      "Epoch: 386, w1: 0.05546292774416944, bias: -0.021513228916767133, loss: 0.6903705640091662\n",
      "Epoch: 387, w1: 0.05546293240299143, bias: -0.021513273060852958, loss: 0.6903705637708805\n",
      "Epoch: 388, w1: 0.05546293695011295, bias: -0.02151331614653462, loss: 0.6903705635383085\n",
      "Epoch: 389, w1: 0.0554629413882121, bias: -0.021513358199188554, loss: 0.6903705633113132\n",
      "Epoch: 390, w1: 0.055462945719902845, bias: -0.02151339924358276, loss: 0.6903705630897607\n",
      "Epoch: 391, w1: 0.055462949947736415, bias: -0.021513439303891404, loss: 0.6903705628735205\n",
      "Epoch: 392, w1: 0.055462954074202916, bias: -0.021513478403709044, loss: 0.6903705626624653\n",
      "Epoch: 393, w1: 0.05546295810173274, bias: -0.021513516566064532, loss: 0.6903705624564708\n",
      "Epoch: 394, w1: 0.055462962032697995, bias: -0.021513553813434578, loss: 0.6903705622554156\n",
      "Epoch: 395, w1: 0.05546296586941393, bias: -0.021513590167756988, loss: 0.6903705620591811\n",
      "Epoch: 396, w1: 0.05546296961414028, bias: -0.02151362565044359, loss: 0.690370561867652\n",
      "Epoch: 397, w1: 0.055462973269082616, bias: -0.02151366028239283, loss: 0.6903705616807153\n",
      "Epoch: 398, w1: 0.0554629768363936, bias: -0.02151369408400209, loss: 0.6903705614982609\n",
      "Epoch: 399, w1: 0.055462980318174274, bias: -0.02151372707517971, loss: 0.6903705613201812\n",
      "Epoch: 400, w1: 0.05546298371647532, bias: -0.0215137592753567, loss: 0.6903705611463716\n",
      "Epoch: 401, w1: 0.055462987033298286, bias: -0.021513790703498195, loss: 0.6903705609767293\n",
      "Epoch: 402, w1: 0.055462990270596674, bias: -0.02151382137811461, loss: 0.6903705608111549\n",
      "Epoch: 403, w1: 0.05546299343027722, bias: -0.02151385131727256, loss: 0.6903705606495502\n",
      "Epoch: 404, w1: 0.05546299651420084, bias: -0.02151388053860549, loss: 0.6903705604918207\n",
      "Epoch: 405, w1: 0.05546299952418393, bias: -0.02151390905932406, loss: 0.690370560337873\n",
      "Epoch: 406, w1: 0.05546300246199928, bias: -0.021513936896226292, loss: 0.6903705601876163\n",
      "Epoch: 407, w1: 0.0554630053293772, bias: -0.021513964065707446, loss: 0.6903705600409626\n",
      "Epoch: 408, w1: 0.05546300812800651, bias: -0.021513990583769703, loss: 0.6903705598978253\n",
      "Epoch: 409, w1: 0.05546301085953555, bias: -0.021514016466031557, loss: 0.69037055975812\n",
      "Epoch: 410, w1: 0.05546301352557308, bias: -0.021514041727737042, loss: 0.6903705596217643\n",
      "Epoch: 411, w1: 0.05546301612768936, bias: -0.021514066383764695, loss: 0.6903705594886783\n",
      "Epoch: 412, w1: 0.055463018667416986, bias: -0.021514090448636326, loss: 0.6903705593587833\n",
      "Epoch: 413, w1: 0.055463021146251776, bias: -0.021514113936525563, loss: 0.6903705592320026\n",
      "Epoch: 414, w1: 0.055463023565653705, bias: -0.02151413686126621, loss: 0.690370559108262\n",
      "Epoch: 415, w1: 0.05546302592704776, bias: -0.021514159236360388, loss: 0.6903705589874881\n",
      "Epoch: 416, w1: 0.05546302823182473, bias: -0.02151418107498649, loss: 0.6903705588696102\n",
      "Epoch: 417, w1: 0.05546303048134206, bias: -0.021514202390006943, loss: 0.6903705587545584\n",
      "Epoch: 418, w1: 0.055463032676924706, bias: -0.021514223193975782, loss: 0.6903705586422655\n",
      "Epoch: 419, w1: 0.05546303481986577, bias: -0.021514243499146046, loss: 0.6903705585326648\n",
      "Epoch: 420, w1: 0.05546303691142743, bias: -0.02151426331747699, loss: 0.6903705584256921\n",
      "Epoch: 421, w1: 0.05546303895284152, bias: -0.021514282660641138, loss: 0.6903705583212844\n",
      "Epoch: 422, w1: 0.055463040945310405, bias: -0.021514301540031144, loss: 0.6903705582193798\n",
      "Epoch: 423, w1: 0.05546304289000761, bias: -0.021514319966766518, loss: 0.6903705581199189\n",
      "Epoch: 424, w1: 0.05546304478807853, bias: -0.021514337951700165, loss: 0.6903705580228424\n",
      "Epoch: 425, w1: 0.05546304664064103, bias: -0.021514355505424777, loss: 0.6903705579280938\n",
      "Epoch: 426, w1: 0.05546304844878631, bias: -0.021514372638279076, loss: 0.6903705578356168\n",
      "Epoch: 427, w1: 0.055463050213579224, bias: -0.021514389360353905, loss: 0.6903705577453572\n",
      "Epoch: 428, w1: 0.05546305193605926, bias: -0.02151440568149816, loss: 0.6903705576572617\n",
      "Epoch: 429, w1: 0.0554630536172409, bias: -0.021514421611324604, loss: 0.6903705575712785\n",
      "Epoch: 430, w1: 0.05546305525811431, bias: -0.021514437159215527, loss: 0.6903705574873569\n",
      "Epoch: 431, w1: 0.055463056859645914, bias: -0.02151445233432826, loss: 0.6903705574054474\n",
      "Epoch: 432, w1: 0.055463058422779016, bias: -0.02151446714560058, loss: 0.6903705573255019\n",
      "Epoch: 433, w1: 0.05546305994843423, bias: -0.021514481601755966, loss: 0.6903705572474732\n",
      "Epoch: 434, w1: 0.055463061437510175, bias: -0.02151449571130875, loss: 0.6903705571713155\n",
      "Epoch: 435, w1: 0.055463062890883826, bias: -0.021514509482569118, loss: 0.6903705570969837\n",
      "Epoch: 436, w1: 0.0554630643094112, bias: -0.021514522923648017, loss: 0.6903705570244342\n",
      "Epoch: 437, w1: 0.055463065693927796, bias: -0.021514536042461913, loss: 0.6903705569536239\n",
      "Epoch: 438, w1: 0.05546306704524903, bias: -0.02151454884673748, loss: 0.6903705568845115\n",
      "Epoch: 439, w1: 0.055463068364170816, bias: -0.021514561344016123, loss: 0.6903705568170565\n",
      "Epoch: 440, w1: 0.055463069651469986, bias: -0.021514573541658435, loss: 0.6903705567512186\n",
      "Epoch: 441, w1: 0.05546307090790471, bias: -0.021514585446848544, loss: 0.6903705566869593\n",
      "Epoch: 442, w1: 0.055463072134214995, bias: -0.021514597066598314, loss: 0.6903705566242406\n",
      "Epoch: 443, w1: 0.0554630733311231, bias: -0.0215146084077515, loss: 0.6903705565630259\n",
      "Epoch: 444, w1: 0.05546307449933399, bias: -0.02151461947698777, loss: 0.6903705565032788\n",
      "Epoch: 445, w1: 0.0554630756395357, bias: -0.021514630280826636, loss: 0.6903705564449644\n",
      "Epoch: 446, w1: 0.0554630767523998, bias: -0.0215146408256313, loss: 0.6903705563880481\n",
      "Epoch: 447, w1: 0.05546307783858172, bias: -0.0215146511176124, loss: 0.6903705563324966\n",
      "Epoch: 448, w1: 0.055463078898721235, bias: -0.021514661162831666, loss: 0.6903705562782766\n",
      "Epoch: 449, w1: 0.05546307993344267, bias: -0.02151467096720549, loss: 0.6903705562253569\n",
      "Epoch: 450, w1: 0.05546308094335551, bias: -0.021514680536508412, loss: 0.690370556173706\n",
      "Epoch: 451, w1: 0.055463081929054595, bias: -0.021514689876376523, loss: 0.6903705561232935\n",
      "Epoch: 452, w1: 0.05546308289112037, bias: -0.02151469899231078, loss: 0.6903705560740896\n",
      "Epoch: 453, w1: 0.05546308383011955, bias: -0.02151470788968025, loss: 0.6903705560260658\n",
      "Epoch: 454, w1: 0.055463084746605176, bias: -0.021514716573725272, loss: 0.6903705559791931\n",
      "Epoch: 455, w1: 0.055463085641117044, bias: -0.021514725049560535, loss: 0.6903705559334443\n",
      "Epoch: 456, w1: 0.055463086514181956, bias: -0.0215147333221781, loss: 0.6903705558887925\n",
      "Epoch: 457, w1: 0.05546308736631417, bias: -0.02151474139645035, loss: 0.6903705558452113\n",
      "Epoch: 458, w1: 0.055463088198015535, bias: -0.02151474927713283, loss: 0.6903705558026748\n",
      "Epoch: 459, w1: 0.05546308900977595, bias: -0.021514756968867076, loss: 0.6903705557611585\n",
      "Epoch: 460, w1: 0.05546308980207351, bias: -0.02151476447618333, loss: 0.6903705557206373\n",
      "Epoch: 461, w1: 0.05546309057537479, bias: -0.021514771803503228, loss: 0.6903705556810878\n",
      "Epoch: 462, w1: 0.05546309133013534, bias: -0.021514778955142377, loss: 0.6903705556424867\n",
      "Epoch: 463, w1: 0.05546309206679965, bias: -0.021514785935312926, loss: 0.6903705556048109\n",
      "Epoch: 464, w1: 0.055463092785801596, bias: -0.021514792748126028, loss: 0.6903705555680387\n",
      "Epoch: 465, w1: 0.05546309348756466, bias: -0.021514799397594264, loss: 0.6903705555321477\n",
      "Epoch: 466, w1: 0.05546309417250217, bias: -0.021514805887634013, loss: 0.6903705554971177\n",
      "Epoch: 467, w1: 0.055463094841017524, bias: -0.02151481222206775, loss: 0.6903705554629272\n",
      "Epoch: 468, w1: 0.05546309549350448, bias: -0.02151481840462631, loss: 0.6903705554295568\n",
      "Epoch: 469, w1: 0.05546309613034733, bias: -0.02151482443895106, loss: 0.6903705553969864\n",
      "Epoch: 470, w1: 0.055463096751921154, bias: -0.021514830328596087, loss: 0.6903705553651968\n",
      "Epoch: 471, w1: 0.05546309735859203, bias: -0.02151483607703024, loss: 0.6903705553341695\n",
      "Epoch: 472, w1: 0.055463097950717286, bias: -0.021514841687639213, loss: 0.6903705553038861\n",
      "Epoch: 473, w1: 0.0554630985286457, bias: -0.021514847163727518, loss: 0.6903705552743288\n",
      "Epoch: 474, w1: 0.05546309909271761, bias: -0.02151485250852044, loss: 0.6903705552454801\n",
      "Epoch: 475, w1: 0.055463099643265255, bias: -0.021514857725165933, loss: 0.690370555217323\n",
      "Epoch: 476, w1: 0.05546310018061292, bias: -0.02151486281673648, loss: 0.6903705551898415\n",
      "Epoch: 477, w1: 0.05546310070507706, bias: -0.02151486778623089, loss: 0.6903705551630185\n",
      "Epoch: 478, w1: 0.0554631012169666, bias: -0.021514872636576074, loss: 0.6903705551368388\n",
      "Epoch: 479, w1: 0.05546310171658299, bias: -0.021514877370628772, loss: 0.6903705551112864\n",
      "Epoch: 480, w1: 0.0554631022042205, bias: -0.021514881991177227, loss: 0.6903705550863471\n",
      "Epoch: 481, w1: 0.05546310268016637, bias: -0.02151488650094283, loss: 0.6903705550620057\n",
      "Epoch: 482, w1: 0.055463103144700904, bias: -0.021514890902581726, loss: 0.6903705550382476\n",
      "Epoch: 483, w1: 0.05546310359809768, bias: -0.021514895198686376, loss: 0.6903705550150595\n",
      "Epoch: 484, w1: 0.0554631040406238, bias: -0.021514899391787076, loss: 0.6903705549924272\n",
      "Epoch: 485, w1: 0.055463104472539826, bias: -0.021514903484353465, loss: 0.6903705549703375\n",
      "Epoch: 486, w1: 0.055463104894100196, bias: -0.021514907478795968, loss: 0.6903705549487773\n",
      "Epoch: 487, w1: 0.05546310530555317, bias: -0.021514911377467215, loss: 0.6903705549277342\n",
      "Epoch: 488, w1: 0.055463105707141094, bias: -0.02151491518266343, loss: 0.6903705549071958\n",
      "Epoch: 489, w1: 0.05546310609910052, bias: -0.021514918896625778, loss: 0.6903705548871496\n",
      "Epoch: 490, w1: 0.055463106481662236, bias: -0.0215149225215417, loss: 0.6903705548675841\n",
      "Epoch: 491, w1: 0.05546310685505164, bias: -0.021514926059546184, loss: 0.6903705548484877\n",
      "Epoch: 492, w1: 0.05546310721948859, bias: -0.021514929512723026, loss: 0.6903705548298493\n",
      "Epoch: 493, w1: 0.05546310757518775, bias: -0.02151493288310606, loss: 0.6903705548116577\n",
      "Epoch: 494, w1: 0.05546310792235864, bias: -0.021514936172680372, loss: 0.6903705547939021\n",
      "Epoch: 495, w1: 0.0554631082612057, bias: -0.021514939383383433, loss: 0.6903705547765724\n",
      "Epoch: 496, w1: 0.05546310859192853, bias: -0.021514942517106277, loss: 0.6903705547596583\n",
      "Epoch: 497, w1: 0.05546310891472192, bias: -0.021514945575694583, loss: 0.6903705547431493\n",
      "Epoch: 498, w1: 0.055463109229775966, bias: -0.021514948560949793, loss: 0.6903705547270365\n",
      "Epoch: 499, w1: 0.05546310953727623, bias: -0.02151495147463015, loss: 0.6903705547113099\n",
      "Epoch: 500, w1: 0.05546310983740383, bias: -0.021514954318451737, loss: 0.6903705546959603\n",
      "Epoch: 501, w1: 0.05546311013033553, bias: -0.021514957094089498, loss: 0.690370554680979\n",
      "Epoch: 502, w1: 0.05546311041624387, bias: -0.021514959803178222, loss: 0.6903705546663567\n",
      "Epoch: 503, w1: 0.05546311069529724, bias: -0.02151496244731349, loss: 0.690370554652085\n",
      "Epoch: 504, w1: 0.05546311096765999, bias: -0.02151496502805264, loss: 0.6903705546381556\n",
      "Epoch: 505, w1: 0.055463111233492526, bias: -0.021514967546915665, loss: 0.6903705546245599\n",
      "Epoch: 506, w1: 0.05546311149295143, bias: -0.02151497000538611, loss: 0.6903705546112903\n",
      "Epoch: 507, w1: 0.05546311174618951, bias: -0.02151497240491196, loss: 0.690370554598339\n",
      "Epoch: 508, w1: 0.055463111993355935, bias: -0.021514974746906473, loss: 0.690370554585698\n",
      "Epoch: 509, w1: 0.05546311223459625, bias: -0.021514977032749034, loss: 0.6903705545733599\n",
      "Epoch: 510, w1: 0.05546311247005259, bias: -0.021514979263785945, loss: 0.6903705545613182\n",
      "Epoch: 511, w1: 0.05546311269986358, bias: -0.021514981441331234, loss: 0.6903705545495648\n",
      "Epoch: 512, w1: 0.05546311292416458, bias: -0.021514983566667423, loss: 0.6903705545380934\n",
      "Epoch: 513, w1: 0.05546311314308773, bias: -0.021514985641046282, loss: 0.690370554526897\n",
      "Epoch: 514, w1: 0.05546311335676194, bias: -0.021514987665689572, loss: 0.690370554515969\n",
      "Epoch: 515, w1: 0.05546311356531307, bias: -0.02151498964178976, loss: 0.690370554505303\n",
      "Epoch: 516, w1: 0.05546311376886396, bias: -0.02151499157051072, loss: 0.6903705544948928\n",
      "Epoch: 517, w1: 0.055463113967534464, bias: -0.021514993452988424, loss: 0.6903705544847322\n",
      "Epoch: 518, w1: 0.055463114161441646, bias: -0.021514995290331608, loss: 0.6903705544748151\n",
      "Epoch: 519, w1: 0.05546311435069968, bias: -0.02151499708362242, loss: 0.6903705544651357\n",
      "Epoch: 520, w1: 0.05546311453542002, bias: -0.021514998833917064, loss: 0.6903705544556886\n",
      "Epoch: 521, w1: 0.055463114715711505, bias: -0.021515000542246424, loss: 0.690370554446468\n",
      "Epoch: 522, w1: 0.055463114891680286, bias: -0.021515002209616663, loss: 0.6903705544374684\n",
      "Epoch: 523, w1: 0.05546311506343004, bias: -0.021515003837009824, loss: 0.6903705544286846\n",
      "Epoch: 524, w1: 0.05546311523106187, bias: -0.021515005425384405, loss: 0.6903705544201113\n",
      "Epoch: 525, w1: 0.05546311539467456, bias: -0.021515006975675915, loss: 0.6903705544117438\n",
      "Epoch: 526, w1: 0.055463115554364444, bias: -0.02151500848879744, loss: 0.6903705544035765\n",
      "Epoch: 527, w1: 0.055463115710225566, bias: -0.021515009965640174, loss: 0.6903705543956052\n",
      "Epoch: 528, w1: 0.05546311586234977, bias: -0.021515011407073938, loss: 0.6903705543878252\n",
      "Epoch: 529, w1: 0.05546311601082661, bias: -0.021515012813947704, loss: 0.6903705543802318\n",
      "Epoch: 530, w1: 0.05546311615574355, bias: -0.02151501418709009, loss: 0.6903705543728202\n",
      "Epoch: 531, w1: 0.05546311629718595, bias: -0.02151501552730984, loss: 0.6903705543655864\n",
      "Epoch: 532, w1: 0.0554631164352371, bias: -0.021515016835396313, loss: 0.6903705543585259\n",
      "Epoch: 533, w1: 0.05546311656997834, bias: -0.02151501811211994, loss: 0.6903705543516349\n",
      "Epoch: 534, w1: 0.05546311670148899, bias: -0.02151501935823268, loss: 0.6903705543449091\n",
      "Epoch: 535, w1: 0.055463116829846525, bias: -0.021515020574468465, loss: 0.6903705543383444\n",
      "Epoch: 536, w1: 0.05546311695512653, bias: -0.021515021761543626, loss: 0.6903705543319373\n",
      "Epoch: 537, w1: 0.05546311707740283, bias: -0.021515022920157324, loss: 0.6903705543256836\n",
      "Epoch: 538, w1: 0.0554631171967474, bias: -0.021515024050991954, loss: 0.6903705543195798\n",
      "Epoch: 539, w1: 0.055463117313230566, bias: -0.021515025154713548, loss: 0.6903705543136227\n",
      "Epoch: 540, w1: 0.05546311742692091, bias: -0.021515026231972174, loss: 0.6903705543078082\n",
      "Epoch: 541, w1: 0.0554631175378854, bias: -0.02151502728340231, loss: 0.6903705543021331\n",
      "Epoch: 542, w1: 0.055463117646189386, bias: -0.02151502830962323, loss: 0.6903705542965941\n",
      "Epoch: 543, w1: 0.05546311775189666, bias: -0.02151502931123935, loss: 0.6903705542911881\n",
      "Epoch: 544, w1: 0.0554631178550695, bias: -0.02151503028884059, loss: 0.6903705542859112\n",
      "Epoch: 545, w1: 0.05546311795576864, bias: -0.021515031243002743, loss: 0.6903705542807613\n",
      "Epoch: 546, w1: 0.05546311805405342, bias: -0.021515032174287782, loss: 0.6903705542757347\n",
      "Epoch: 547, w1: 0.0554631181499817, bias: -0.021515033083244216, loss: 0.6903705542708286\n",
      "Epoch: 548, w1: 0.05546311824360998, bias: -0.021515033970407396, loss: 0.6903705542660402\n",
      "Epoch: 549, w1: 0.055463118334993414, bias: -0.02151503483629984, loss: 0.6903705542613666\n",
      "Epoch: 550, w1: 0.05546311842418586, bias: -0.021515035681431538, loss: 0.6903705542568049\n",
      "Epoch: 551, w1: 0.055463118511239785, bias: -0.02151503650630025, loss: 0.6903705542523527\n",
      "Epoch: 552, w1: 0.055463118596206507, bias: -0.021515037311391805, loss: 0.6903705542480072\n",
      "Epoch: 553, w1: 0.055463118679136066, bias: -0.02151503809718039, loss: 0.690370554243766\n",
      "Epoch: 554, w1: 0.05546311876007728, bias: -0.021515038864128803, loss: 0.6903705542396263\n",
      "Epoch: 555, w1: 0.05546311883907785, bias: -0.021515039612688764, loss: 0.690370554235586\n",
      "Epoch: 556, w1: 0.05546311891618429, bias: -0.021515040343301157, loss: 0.6903705542316425\n",
      "Epoch: 557, w1: 0.05546311899144201, bias: -0.0215150410563963, loss: 0.6903705542277937\n",
      "Epoch: 558, w1: 0.05546311906489533, bias: -0.02151504175239418, loss: 0.690370554224037\n",
      "Epoch: 559, w1: 0.055463119136587545, bias: -0.02151504243170473, loss: 0.6903705542203706\n",
      "Epoch: 560, w1: 0.05546311920656086, bias: -0.021515043094728042, loss: 0.6903705542167918\n",
      "Epoch: 561, w1: 0.05546311927485646, bias: -0.021515043741854627, loss: 0.690370554213299\n",
      "Epoch: 562, w1: 0.05546311934151462, bias: -0.021515044373465624, loss: 0.6903705542098898\n",
      "Epoch: 563, w1: 0.05546311940657456, bias: -0.021515044989933032, loss: 0.6903705542065625\n",
      "Epoch: 564, w1: 0.05546311947007462, bias: -0.02151504559161994, loss: 0.690370554203315\n",
      "Epoch: 565, w1: 0.055463119532052206, bias: -0.02151504617888073, loss: 0.6903705542001454\n",
      "Epoch: 566, w1: 0.05546311959254381, bias: -0.021515046752061277, loss: 0.6903705541970515\n",
      "Epoch: 567, w1: 0.05546311965158504, bias: -0.021515047311499176, loss: 0.690370554194032\n",
      "Epoch: 568, w1: 0.05546311970921071, bias: -0.021515047857523922, loss: 0.6903705541910847\n",
      "Epoch: 569, w1: 0.055463119765454726, bias: -0.021515048390457113, loss: 0.6903705541882083\n",
      "Epoch: 570, w1: 0.055463119820350244, bias: -0.021515048910612625, loss: 0.6903705541854007\n",
      "Epoch: 571, w1: 0.05546311987392957, bias: -0.021515049418296826, loss: 0.6903705541826605\n",
      "Epoch: 572, w1: 0.05546311992622427, bias: -0.021515049913808725, loss: 0.690370554179986\n",
      "Epoch: 573, w1: 0.05546311997726512, bias: -0.02151505039744017, loss: 0.6903705541773757\n",
      "Epoch: 574, w1: 0.055463120027082244, bias: -0.021515050869476006, loss: 0.6903705541748278\n",
      "Epoch: 575, w1: 0.05546312007570494, bias: -0.02151505133019425, loss: 0.6903705541723412\n",
      "Epoch: 576, w1: 0.05546312012316186, bias: -0.02151505177986626, loss: 0.690370554169914\n",
      "Epoch: 577, w1: 0.05546312016948093, bias: -0.021515052218756874, loss: 0.6903705541675453\n",
      "Epoch: 578, w1: 0.05546312021468946, bias: -0.021515052647124593, loss: 0.6903705541652331\n",
      "Epoch: 579, w1: 0.055463120258814044, bias: -0.021515053065221716, loss: 0.6903705541629765\n",
      "Epoch: 580, w1: 0.05546312030188072, bias: -0.021515053473294486, loss: 0.6903705541607739\n",
      "Epoch: 581, w1: 0.055463120343914804, bias: -0.021515053871583253, loss: 0.6903705541586241\n",
      "Epoch: 582, w1: 0.055463120384941084, bias: -0.021515054260322596, loss: 0.690370554156526\n",
      "Epoch: 583, w1: 0.05546312042498371, bias: -0.021515054639741477, loss: 0.6903705541544781\n",
      "Epoch: 584, w1: 0.055463120464066276, bias: -0.02151505501006336, loss: 0.6903705541524792\n",
      "Epoch: 585, w1: 0.05546312050221178, bias: -0.021515055371506366, loss: 0.6903705541505284\n",
      "Epoch: 586, w1: 0.05546312053944269, bias: -0.021515055724283364, loss: 0.6903705541486241\n",
      "Epoch: 587, w1: 0.05546312057578097, bias: -0.021515056068602136, loss: 0.6903705541467658\n",
      "Epoch: 588, w1: 0.055463120611247994, bias: -0.021515056404665476, loss: 0.6903705541449519\n",
      "Epoch: 589, w1: 0.055463120645864644, bias: -0.021515056732671324, loss: 0.6903705541431814\n",
      "Epoch: 590, w1: 0.05546312067965135, bias: -0.021515057052812862, loss: 0.6903705541414534\n",
      "Epoch: 591, w1: 0.05546312071262795, bias: -0.021515057365278645, loss: 0.690370554139767\n",
      "Epoch: 592, w1: 0.055463120744813924, bias: -0.021515057670252708, loss: 0.6903705541381209\n",
      "Epoch: 593, w1: 0.055463120776228184, bias: -0.021515057967914673, loss: 0.6903705541365143\n",
      "Epoch: 594, w1: 0.05546312080688927, bias: -0.02151505825843986, loss: 0.6903705541349462\n",
      "Epoch: 595, w1: 0.055463120836815205, bias: -0.02151505854199938, loss: 0.6903705541334156\n",
      "Epoch: 596, w1: 0.05546312086602363, bias: -0.02151505881876024, loss: 0.6903705541319218\n",
      "Epoch: 597, w1: 0.055463120894531766, bias: -0.021515059088885447, loss: 0.6903705541304639\n",
      "Epoch: 598, w1: 0.05546312092235638, bias: -0.0215150593525341, loss: 0.6903705541290407\n",
      "Epoch: 599, w1: 0.05546312094951387, bias: -0.021515059609861473, loss: 0.6903705541276519\n",
      "Epoch: 600, w1: 0.05546312097602023, bias: -0.021515059861019138, loss: 0.6903705541262962\n",
      "Epoch: 601, w1: 0.05546312100189106, bias: -0.021515060106155014, loss: 0.6903705541249732\n",
      "Epoch: 602, w1: 0.05546312102714161, bias: -0.02151506034541348, loss: 0.6903705541236818\n",
      "Epoch: 603, w1: 0.05546312105178675, bias: -0.021515060578935458, loss: 0.6903705541224214\n",
      "Epoch: 604, w1: 0.055463121075841, bias: -0.021515060806858482, loss: 0.6903705541211912\n",
      "Epoch: 605, w1: 0.05546312109931853, bias: -0.021515061029316794, loss: 0.6903705541199905\n",
      "Epoch: 606, w1: 0.055463121122233144, bias: -0.021515061246441418, loss: 0.6903705541188184\n",
      "Epoch: 607, w1: 0.05546312114459835, bias: -0.021515061458360234, loss: 0.6903705541176747\n",
      "Epoch: 608, w1: 0.05546312116642734, bias: -0.02151506166519806, loss: 0.6903705541165582\n",
      "Epoch: 609, w1: 0.05546312118773296, bias: -0.021515061867076718, loss: 0.6903705541154687\n",
      "Epoch: 610, w1: 0.05546312120852774, bias: -0.021515062064115104, loss: 0.6903705541144051\n",
      "Epoch: 611, w1: 0.05546312122882395, bias: -0.02151506225642927, loss: 0.690370554113367\n",
      "Epoch: 612, w1: 0.05546312124863352, bias: -0.021515062444132493, loss: 0.690370554112354\n",
      "Epoch: 613, w1: 0.055463121267968145, bias: -0.021515062627335317, loss: 0.690370554111365\n",
      "Epoch: 614, w1: 0.05546312128683922, bias: -0.021515062806145648, loss: 0.6903705541103999\n",
      "Epoch: 615, w1: 0.05546312130525781, bias: -0.0215150629806688, loss: 0.6903705541094581\n",
      "Epoch: 616, w1: 0.055463121323234804, bias: -0.021515063151007565, loss: 0.6903705541085386\n",
      "Epoch: 617, w1: 0.05546312134078078, bias: -0.021515063317262266, loss: 0.6903705541076413\n",
      "Epoch: 618, w1: 0.05546312135790608, bias: -0.021515063479530822, loss: 0.6903705541067655\n",
      "Epoch: 619, w1: 0.05546312137462076, bias: -0.021515063637908807, loss: 0.6903705541059106\n",
      "Epoch: 620, w1: 0.05546312139093471, bias: -0.0215150637924895, loss: 0.6903705541050762\n",
      "Epoch: 621, w1: 0.05546312140685751, bias: -0.021515063943363947, loss: 0.6903705541042621\n",
      "Epoch: 622, w1: 0.05546312142239852, bias: -0.02151506409062101, loss: 0.6903705541034671\n",
      "Epoch: 623, w1: 0.055463121437566945, bias: -0.02151506423434742, loss: 0.6903705541026913\n",
      "Epoch: 624, w1: 0.055463121452371686, bias: -0.02151506437462783, loss: 0.6903705541019343\n",
      "Epoch: 625, w1: 0.05546312146682145, bias: -0.021515064511544852, loss: 0.6903705541011952\n",
      "Epoch: 626, w1: 0.05546312148092477, bias: -0.021515064645179136, loss: 0.690370554100474\n",
      "Epoch: 627, w1: 0.05546312149468996, bias: -0.02151506477560939, loss: 0.6903705540997699\n",
      "Epoch: 628, w1: 0.055463121508125095, bias: -0.02151506490291243, loss: 0.6903705540990828\n",
      "Epoch: 629, w1: 0.055463121521238126, bias: -0.021515065027163237, loss: 0.6903705540984122\n",
      "Epoch: 630, w1: 0.05546312153403676, bias: -0.02151506514843499, loss: 0.6903705540977576\n",
      "Epoch: 631, w1: 0.05546312154652851, bias: -0.021515065266799117, loss: 0.6903705540971187\n",
      "Epoch: 632, w1: 0.05546312155872076, bias: -0.02151506538232533, loss: 0.6903705540964952\n",
      "Epoch: 633, w1: 0.05546312157062071, bias: -0.021515065495081673, loss: 0.6903705540958865\n",
      "Epoch: 634, w1: 0.05546312158223531, bias: -0.021515065605134553, loss: 0.6903705540952926\n",
      "Epoch: 635, w1: 0.05546312159357147, bias: -0.021515065712548794, loss: 0.6903705540947129\n",
      "Epoch: 636, w1: 0.05546312160463582, bias: -0.021515065817387657, loss: 0.6903705540941468\n",
      "Epoch: 637, w1: 0.05546312161543489, bias: -0.021515065919712893, loss: 0.6903705540935947\n",
      "Epoch: 638, w1: 0.05546312162597505, bias: -0.021515066019584764, loss: 0.6903705540930556\n",
      "Epoch: 639, w1: 0.05546312163626248, bias: -0.021515066117062095, loss: 0.6903705540925295\n",
      "Epoch: 640, w1: 0.055463121646303265, bias: -0.021515066212202297, loss: 0.690370554092016\n",
      "Epoch: 641, w1: 0.05546312165610331, bias: -0.021515066305061406, loss: 0.6903705540915149\n",
      "Epoch: 642, w1: 0.055463121665668386, bias: -0.021515066395694112, loss: 0.6903705540910257\n",
      "Epoch: 643, w1: 0.05546312167500415, bias: -0.0215150664841538, loss: 0.6903705540905483\n",
      "Epoch: 644, w1: 0.055463121684116046, bias: -0.021515066570492566, loss: 0.6903705540900823\n",
      "Epoch: 645, w1: 0.05546312169300949, bias: -0.021515066654761262, loss: 0.6903705540896272\n",
      "Epoch: 646, w1: 0.0554631217016897, bias: -0.02151506673700952, loss: 0.6903705540891835\n",
      "Epoch: 647, w1: 0.055463121710161795, bias: -0.021515066817285784, loss: 0.69037055408875\n",
      "Epoch: 648, w1: 0.05546312171843075, bias: -0.021515066895637334, loss: 0.6903705540883273\n",
      "Epoch: 649, w1: 0.05546312172650146, bias: -0.021515066972110322, loss: 0.6903705540879145\n",
      "Epoch: 650, w1: 0.05546312173437869, bias: -0.02151506704674978, loss: 0.6903705540875116\n",
      "Epoch: 651, w1: 0.05546312174206702, bias: -0.021515067119599673, loss: 0.6903705540871184\n",
      "Epoch: 652, w1: 0.05546312174957099, bias: -0.02151506719070291, loss: 0.6903705540867345\n",
      "Epoch: 653, w1: 0.05546312175689509, bias: -0.021515067260101366, loss: 0.69037055408636\n",
      "Epoch: 654, w1: 0.05546312176404356, bias: -0.021515067327835917, loss: 0.6903705540859945\n",
      "Epoch: 655, w1: 0.05546312177102065, bias: -0.021515067393946454, loss: 0.6903705540856375\n",
      "Epoch: 656, w1: 0.055463121777830464, bias: -0.021515067458471916, loss: 0.6903705540852894\n",
      "Epoch: 657, w1: 0.055463121784477, bias: -0.021515067521450305, loss: 0.6903705540849493\n",
      "Epoch: 658, w1: 0.055463121790964166, bias: -0.02151506758291872, loss: 0.6903705540846176\n",
      "Epoch: 659, w1: 0.05546312179729581, bias: -0.021515067642913357, loss: 0.6903705540842937\n",
      "Epoch: 660, w1: 0.055463121803475644, bias: -0.021515067701469555, loss: 0.6903705540839778\n",
      "Epoch: 661, w1: 0.0554631218095073, bias: -0.021515067758621803, loss: 0.6903705540836692\n",
      "Epoch: 662, w1: 0.055463121815394346, bias: -0.021515067814403762, loss: 0.6903705540833682\n",
      "Epoch: 663, w1: 0.05546312182114024, bias: -0.021515067868848284, loss: 0.6903705540830742\n",
      "Epoch: 664, w1: 0.055463121826748375, bias: -0.021515067921987437, loss: 0.6903705540827874\n",
      "Epoch: 665, w1: 0.055463121832222045, bias: -0.021515067973852522, loss: 0.6903705540825076\n",
      "Epoch: 666, w1: 0.05546312183756449, bias: -0.021515068024474084, loss: 0.6903705540822344\n",
      "Epoch: 667, w1: 0.05546312184277882, bias: -0.021515068073881934, loss: 0.6903705540819676\n",
      "Epoch: 668, w1: 0.055463121847868155, bias: -0.02151506812210518, loss: 0.6903705540817073\n",
      "Epoch: 669, w1: 0.05546312185283545, bias: -0.021515068169172216, loss: 0.6903705540814533\n",
      "Epoch: 670, w1: 0.055463121857683644, bias: -0.021515068215110768, loss: 0.6903705540812054\n",
      "Epoch: 671, w1: 0.055463121862415615, bias: -0.02151506825994789, loss: 0.6903705540809634\n",
      "Epoch: 672, w1: 0.05546312186703413, bias: -0.021515068303709993, loss: 0.6903705540807271\n",
      "Epoch: 673, w1: 0.0554631218715419, bias: -0.02151506834642285, loss: 0.6903705540804966\n",
      "Epoch: 674, w1: 0.055463121875941594, bias: -0.021515068388111618, loss: 0.6903705540802716\n",
      "Epoch: 675, w1: 0.05546312188023579, bias: -0.02151506842880085, loss: 0.6903705540800519\n",
      "Epoch: 676, w1: 0.05546312188442705, bias: -0.021515068468514514, loss: 0.6903705540798377\n",
      "Epoch: 677, w1: 0.055463121888517805, bias: -0.021515068507275997, loss: 0.6903705540796284\n",
      "Epoch: 678, w1: 0.055463121892510486, bias: -0.02151506854510813, loss: 0.6903705540794242\n",
      "Epoch: 679, w1: 0.05546312189640743, bias: -0.021515068582033194, loss: 0.6903705540792249\n",
      "Epoch: 680, w1: 0.05546312190021097, bias: -0.02151506861807294, loss: 0.6903705540790304\n",
      "Epoch: 681, w1: 0.055463121903923274, bias: -0.02151506865324859, loss: 0.6903705540788406\n",
      "Epoch: 682, w1: 0.0554631219075466, bias: -0.021515068687580866, loss: 0.6903705540786552\n",
      "Epoch: 683, w1: 0.055463121911083046, bias: -0.021515068721089985, loss: 0.6903705540784743\n",
      "Epoch: 684, w1: 0.055463121914534695, bias: -0.021515068753795687, loss: 0.6903705540782977\n",
      "Epoch: 685, w1: 0.0554631219179036, bias: -0.021515068785717233, loss: 0.6903705540781256\n",
      "Epoch: 686, w1: 0.05546312192119171, bias: -0.021515068816873425, loss: 0.6903705540779574\n",
      "Epoch: 687, w1: 0.055463121924401, bias: -0.02151506884728261, loss: 0.6903705540777932\n",
      "Epoch: 688, w1: 0.05546312192753332, bias: -0.021515068876962702, loss: 0.6903705540776331\n",
      "Epoch: 689, w1: 0.05546312193059058, bias: -0.02151506890593118, loss: 0.6903705540774768\n",
      "Epoch: 690, w1: 0.0554631219335745, bias: -0.021515068934205107, loss: 0.6903705540773241\n",
      "Epoch: 691, w1: 0.055463121936486906, bias: -0.021515068961801134, loss: 0.6903705540771751\n",
      "Epoch: 692, w1: 0.05546312193932947, bias: -0.021515068988735515, loss: 0.6903705540770297\n",
      "Epoch: 693, w1: 0.05546312194210387, bias: -0.021515069015024115, loss: 0.6903705540768877\n",
      "Epoch: 694, w1: 0.05546312194481179, bias: -0.021515069040682414, loss: 0.6903705540767494\n",
      "Epoch: 695, w1: 0.055463121947454744, bias: -0.021515069065725527, loss: 0.6903705540766142\n",
      "Epoch: 696, w1: 0.05546312195003435, bias: -0.021515069090168204, loss: 0.6903705540764822\n",
      "Epoch: 697, w1: 0.05546312195255209, bias: -0.02151506911402484, loss: 0.6903705540763534\n",
      "Epoch: 698, w1: 0.05546312195500949, bias: -0.021515069137309484, loss: 0.6903705540762278\n",
      "Epoch: 699, w1: 0.05546312195740795, bias: -0.021515069160035854, loss: 0.690370554076105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.05546312195740795, -0.021515069160035854)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_dcnt(X_train_scaled, y_train, 700, 0.61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ac4a18-24d4-4667-897f-12ceca8dd43a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0dfa62-e3d8-4ed6-aae5-26551e99a005",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
