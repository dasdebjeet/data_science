{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e53f40-9251-4628-9894-e10557fa7926",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b59a4b06-c8cf-4530-857e-1beb7f83ee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, spacy ## spacy uses stemming and nltk uses lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "201f88b3-9508-45cf-8e25-486b171fb4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8345bd7-a334-4236-bcca-fefc50eac6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat\n",
      "eats  |  eat\n",
      "eat  |  eat\n",
      "ate  |  ate\n",
      "adjustable  |  adjust\n",
      "rubbing  |  rub\n",
      "ability  |  abil\n",
      "fucking  |  fuck\n"
     ]
    }
   ],
   "source": [
    "words = [\"eating\", \"eats\", \"eat\", \"ate\", \"adjustable\", \"rubbing\", \"ability\", \"fucking\"]\n",
    "\n",
    "for word in words:\n",
    "    print(word, \" | \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9443cd41-7de4-41e6-b1cb-942af4e6700c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a2be5b0-ce2d-46ee-9137-ef15e937b59e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating  |  eat  |  9837207709914848172\n",
      "eats  |  eat  |  9837207709914848172\n",
      "eat  |  eat  |  9837207709914848172\n",
      "ate  |  eat  |  9837207709914848172\n",
      "adjustable  |  adjustable  |  6033511944150694480\n",
      "rubbing  |  rub  |  3833470278404931097\n",
      "ability  |  ability  |  11565809527369121409\n",
      "fucking  |  fuck  |  12903434802346126505\n",
      "better  |  well  |  4525988469032889948\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"eating eats eat ate adjustable rubbing ability fucking better\")\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_, \" | \", token.lemma) ## token | lemmatization | unique hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27af0846-0476-4235-9a3f-4129efc9688e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I  |  I\n",
      "talk  |  talk\n",
      "for  |  for\n",
      "3  |  3\n",
      "hrs  |  hrs\n",
      ".  |  .\n",
      "although  |  although\n",
      "taking  |  take\n",
      "is  |  be\n",
      "n't  |  not\n",
      "my  |  my\n",
      "thing  |  thing\n",
      ",  |  ,\n",
      "I  |  I\n",
      "became  |  become\n",
      "talkative  |  talkative\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"I talk for 3 hrs. although taking isn't my thing, I became talkative\")\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_) ## token | lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267c947c-1626-435b-90ca-605c5e313d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ff19f05-c4dc-40cb-99a1-e95a5a04b6e2",
   "metadata": {},
   "source": [
    "## Custom lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b1bf46b-9852-442e-8bf1-286fd2b8ffa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  bro\n",
      ",  |  ,\n",
      "its  |  its\n",
      "late  |  late\n",
      "to  |  to\n",
      "go  |  go\n",
      "Home  |  home\n",
      ".  |  .\n",
      "Bruh  |  bruh\n",
      "chill  |  chill\n",
      "up  |  up\n",
      "there  |  there\n",
      "still  |  still\n",
      "time  |  time\n",
      ".  |  .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Bro, its late to go Home. Bruh chill up there still time.\")\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_) ## token | lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7539928c-1cc8-4167-ab8c-0c4af77a4bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ar = nlp.get_pipe('attribute_ruler')\n",
    "ar.add([[{\"TEXT\": \"Bro\"}], [{\"TEXT\": \"Bruh\"}]], {\"LEMMA\": \"Brother\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "33470279-3447-4eab-8537-e83d47288c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bro  |  Brother\n",
      ",  |  ,\n",
      "its  |  its\n",
      "late  |  late\n",
      "to  |  to\n",
      "go  |  go\n",
      "Home  |  home\n",
      ".  |  .\n",
      "Bruh  |  Brother\n",
      "chill  |  chill\n",
      "up  |  up\n",
      "there  |  there\n",
      "still  |  still\n",
      "time  |  time\n",
      ".  |  .\n"
     ]
    }
   ],
   "source": [
    "## now \"Bro and bruh\" will change to Brother\n",
    "doc = nlp(\"Bro, its late to go Home. Bruh chill up there still time.\")\n",
    "for token in doc:\n",
    "    print(token, \" | \", token.lemma_) ## token | lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335f1a7d-49ef-461f-89c7-0c6660d14a9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d914a6a-0bce-400f-9265-ca0cf9273994",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21cb95b6-c13c-4638-9726-57f4c0d09153",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Q1. Convert these list of words into base form using Stemming and Lemmatization and observe the transformations\n",
    "\n",
    "# using stemming in nltk\n",
    "lst_words = ['running', 'painting', 'walking', 'dressing', 'likely', 'children', 'whom', 'good', 'ate', 'fishing']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f6020a65-10ee-4acf-8057-55aeec926bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run\n",
      "painting  |  paint\n",
      "walking  |  walk\n",
      "dressing  |  dress\n",
      "likely  |  like\n",
      "children  |  children\n",
      "whom  |  whom\n",
      "good  |  good\n",
      "ate  |  ate\n",
      "fishing  |  fish\n"
     ]
    }
   ],
   "source": [
    "for word in lst_words:\n",
    "    print(word, \" | \", stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39520287-ad81-438e-bbd6-6e47ec75f375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running  |  run\n",
      "painting  |  paint\n",
      "walking  |  walk\n",
      "dressing  |  dress\n",
      "likely  |  likely\n",
      "children  |  child\n",
      "who  |  who\n",
      "good  |  good\n",
      "ate  |  eat\n",
      "fishing  |  fishing\n"
     ]
    }
   ],
   "source": [
    "## Q2. Write a short note on the words that have different base words using stemming and Lemmatization\n",
    "\n",
    "#using lemmatization in spacy\n",
    "doc = nlp(\"running painting walking dressing likely children who good ate fishing\")\n",
    "for token in doc:\n",
    "    print(token.text, \" | \", token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe23658-3c42-4386-80f9-af0f5e577e48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a764c63-2d58-4461-9e06-4749cc299bbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "66c75796-329a-4bbb-a133-4c453d5fd3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latha is veri multi talent girl.sh is good at mani skill like danc , run , sing , playing.sh also like eat pav bhagi . she ha a habit of fish and swim too.besid all thi , she is a wonder at cook too .\n"
     ]
    }
   ],
   "source": [
    "## Q3. Convert the given text into it's base form using both stemming and lemmatization\n",
    "\n",
    "### using nltk\n",
    "text = \"\"\"Latha is very multi talented girl.She is good at many skills like dancing, running, singing, playing.She also likes eating Pav Bhagi. she has a \n",
    "habit of fishing and swimming too.Besides all this, she is a wonderful at cooking too.\n",
    "\"\"\"\n",
    "\n",
    "word_tokenized = nltk.word_tokenize(text)\n",
    "\n",
    "nltk_stem_word_lst = []\n",
    "for word in word_tokenized:\n",
    "    nltk_stem_word_lst.append(stemmer.stem(word))\n",
    "\n",
    "print(\" \".join(nltk_stem_word_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ffd59a7-a3cf-49e5-a9a6-22e13f60eff2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "46e1db70-ab83-4838-b838-899b3af5028e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latha be very multi talented girl . she be good at many skill like dancing , running , singing , play . she also like eat Pav Bhagi . she have a \n",
      " habit of fishing and swim too . besides all this , she be a wonderful at cook too . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### using spacy\n",
    "\n",
    "doc = nlp(text)\n",
    "all_word_lst = []\n",
    "for token in doc:\n",
    "    all_word_lst.append(token.lemma_)\n",
    "\n",
    "print(\" \".join(all_word_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29fbb96-5072-469d-abeb-c518523fd6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
